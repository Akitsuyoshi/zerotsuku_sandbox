{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def AND(x1, x2):\\n    x = np.array([x1, x2])\\n    w = np.array([0.5, 0.5])\\n    b = -0.7\\n    tmp = np.sum(w * x) + b\\n    if tmp <= 0:\\n        return 0\\n    elif tmp > 0:\\n        return 1\\n\\n\\ndef NAND(x1, x2):\\n    x = np.array([x1, x2])\\n    w = np.array([-0.5, -0.5])\\n    b = 0.7\\n    tmp = np.sum(w * x) + b\\n    if tmp <= 0:\\n        return 0\\n    elif tmp > 0:\\n        return 1\\n\\n\\ndef OR(x1, x2):\\n    x = np.array([x1, x2])\\n    w = np.array([0.5, 0.5])\\n    b = -0.2\\n    tmp = np.sum(w * x) + b\\n    if tmp <= 0:\\n        return 0\\n    elif tmp > 0:\\n        return 1\\n\\n\\ndef XOR(x1, x2):\\n    return AND(NAND(x1, x2), OR(x1, x2))\";\n",
       "                var nbb_formatted_code = \"def AND(x1, x2):\\n    x = np.array([x1, x2])\\n    w = np.array([0.5, 0.5])\\n    b = -0.7\\n    tmp = np.sum(w * x) + b\\n    if tmp <= 0:\\n        return 0\\n    elif tmp > 0:\\n        return 1\\n\\n\\ndef NAND(x1, x2):\\n    x = np.array([x1, x2])\\n    w = np.array([-0.5, -0.5])\\n    b = 0.7\\n    tmp = np.sum(w * x) + b\\n    if tmp <= 0:\\n        return 0\\n    elif tmp > 0:\\n        return 1\\n\\n\\ndef OR(x1, x2):\\n    x = np.array([x1, x2])\\n    w = np.array([0.5, 0.5])\\n    b = -0.2\\n    tmp = np.sum(w * x) + b\\n    if tmp <= 0:\\n        return 0\\n    elif tmp > 0:\\n        return 1\\n\\n\\ndef XOR(x1, x2):\\n    return AND(NAND(x1, x2), OR(x1, x2))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w * x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    elif tmp > 0:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-0.5, -0.5])\n",
    "    b = 0.7\n",
    "    tmp = np.sum(w * x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    elif tmp > 0:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w * x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    elif tmp > 0:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def step_function(x):\\n    #     y = x > 0\\n    #     return y.astype(np.int)\\n    return np.array(x > 0, dtype=int)\\n\\n\\ndef sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n\\ndef relu(x):\\n    return np.maximum(0, x)\\n\\n\\ndef identity_function(x):\\n    return x\\n\\n\\ndef softmax(x):\\n    max_x = np.max(x)\\n    exp_x = np.exp(x - max_x)\\n    return exp_x / np.sum(exp_x)\";\n",
       "                var nbb_formatted_code = \"def step_function(x):\\n    #     y = x > 0\\n    #     return y.astype(np.int)\\n    return np.array(x > 0, dtype=int)\\n\\n\\ndef sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n\\ndef relu(x):\\n    return np.maximum(0, x)\\n\\n\\ndef identity_function(x):\\n    return x\\n\\n\\ndef softmax(x):\\n    max_x = np.max(x)\\n    exp_x = np.exp(x - max_x)\\n    return exp_x / np.sum(exp_x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def step_function(x):\n",
    "    #     y = x > 0\n",
    "    #     return y.astype(np.int)\n",
    "    return np.array(x > 0, dtype=int)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    max_x = np.max(x)\n",
    "    exp_x = np.exp(x - max_x)\n",
    "    return exp_x / np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize activation functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"x = np.arange(-5, 5, 0.1)\\ny = relu(x)\\nplt.plot(x, y)\\n# plt.ylim(-0.1, 1.1)\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"x = np.arange(-5, 5, 0.1)\\ny = relu(x)\\nplt.plot(x, y)\\n# plt.ylim(-0.1, 1.1)\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5, 5, 0.1)\n",
    "y = relu(x)\n",
    "plt.plot(x, y)\n",
    "# plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def init_network():\\n    network = {}\\n    network[\\\"W1\\\"] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\\n    network[\\\"b1\\\"] = np.array([0.1, 0.2, 0.3])\\n    network[\\\"W2\\\"] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\\n    network[\\\"b2\\\"] = np.array([0.1, 0.2])\\n    network[\\\"W3\\\"] = np.array([[0.1, 0.3], [0.2, 0.4]])\\n    network[\\\"b3\\\"] = np.array([0.1, 0.2])\\n    return network\\n\\n\\ndef forward(network, x):\\n    W1, W2, W3 = network[\\\"W1\\\"], network[\\\"W2\\\"], network[\\\"W3\\\"]\\n    b1, b2, b3 = network[\\\"b1\\\"], network[\\\"b2\\\"], network[\\\"b3\\\"]\\n\\n    x = np.dot(x, W1) + b1\\n    x = sigmoid(x)\\n    x = np.dot(x, W2) + b2\\n    x = sigmoid(x)\\n    x = np.dot(x, W3) + b3\\n    return identity_function(x)\\n\\n\\nnetwork = init_network()\\nx = np.array([1, 0.5])\\ny = forward(network, x)\\nprint(y)\";\n",
       "                var nbb_formatted_code = \"def init_network():\\n    network = {}\\n    network[\\\"W1\\\"] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\\n    network[\\\"b1\\\"] = np.array([0.1, 0.2, 0.3])\\n    network[\\\"W2\\\"] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\\n    network[\\\"b2\\\"] = np.array([0.1, 0.2])\\n    network[\\\"W3\\\"] = np.array([[0.1, 0.3], [0.2, 0.4]])\\n    network[\\\"b3\\\"] = np.array([0.1, 0.2])\\n    return network\\n\\n\\ndef forward(network, x):\\n    W1, W2, W3 = network[\\\"W1\\\"], network[\\\"W2\\\"], network[\\\"W3\\\"]\\n    b1, b2, b3 = network[\\\"b1\\\"], network[\\\"b2\\\"], network[\\\"b3\\\"]\\n\\n    x = np.dot(x, W1) + b1\\n    x = sigmoid(x)\\n    x = np.dot(x, W2) + b2\\n    x = sigmoid(x)\\n    x = np.dot(x, W3) + b3\\n    return identity_function(x)\\n\\n\\nnetwork = init_network()\\nx = np.array([1, 0.5])\\ny = forward(network, x)\\nprint(y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network[\"W1\"] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network[\"b1\"] = np.array([0.1, 0.2, 0.3])\n",
    "    network[\"W2\"] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network[\"b2\"] = np.array([0.1, 0.2])\n",
    "    network[\"W3\"] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network[\"b3\"] = np.array([0.1, 0.2])\n",
    "    return network\n",
    "\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network[\"W1\"], network[\"W2\"], network[\"W3\"]\n",
    "    b1, b2, b3 = network[\"b1\"], network[\"b2\"], network[\"b3\"]\n",
    "\n",
    "    x = np.dot(x, W1) + b1\n",
    "    x = sigmoid(x)\n",
    "    x = np.dot(x, W2) + b2\n",
    "    x = sigmoid(x)\n",
    "    x = np.dot(x, W3) + b3\n",
    "    return identity_function(x)\n",
    "\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0xFFFF6EFA1250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"import sys, os\\n\\nsys.path.append(os.pardir)\\nfrom dataset.mnist import load_mnist\\nfrom PIL import Image\\n\\n\\ndef img_show(img):\\n    img = Image.fromarray(np.uint8(img))\\n    img.show()\\n\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\\nimg = x_train[0]\\nlabel = t_train[0]\\nprint(label)\\n\\nprint(img.shape)\\nimg = img.reshape(28, 28)\\nimg_show(img)\";\n",
       "                var nbb_formatted_code = \"import sys, os\\n\\nsys.path.append(os.pardir)\\nfrom dataset.mnist import load_mnist\\nfrom PIL import Image\\n\\n\\ndef img_show(img):\\n    img = Image.fromarray(np.uint8(img))\\n    img.show()\\n\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\\nimg = x_train[0]\\nlabel = t_train[0]\\nprint(label)\\n\\nprint(img.shape)\\nimg = img.reshape(28, 28)\\nimg_show(img)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    img.show()\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)\n",
    "\n",
    "print(img.shape)\n",
    "img = img.reshape(28, 28)\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference using pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"import pickle\\n\\n\\ndef get_data():\\n    (x_train, t_train), (x_test, t_test) = load_mnist(\\n        normalize=True, flatten=True, one_hot_label=False\\n    )\\n    return x_test, t_test\\n\\n\\ndef init_network():\\n    with open(\\\"sample_weight.pkl\\\", \\\"rb\\\") as f:\\n        network = pickle.load(f)\\n    return network\";\n",
       "                var nbb_formatted_code = \"import pickle\\n\\n\\ndef get_data():\\n    (x_train, t_train), (x_test, t_test) = load_mnist(\\n        normalize=True, flatten=True, one_hot_label=False\\n    )\\n    return x_test, t_test\\n\\n\\ndef init_network():\\n    with open(\\\"sample_weight.pkl\\\", \\\"rb\\\") as f:\\n        network = pickle.load(f)\\n    return network\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "        normalize=True, flatten=True, one_hot_label=False\n",
    "    )\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.9352\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"x, t = get_data()\\nnetwork = init_network()\\n\\nbatch_size = 100\\nacc_cnt = 0\\nfor i in range(0, len(x), batch_size):\\n    x_batch = x[i : i + batch_size]\\n    y = forward(network, x_batch)\\n    p = np.argmax(y, axis=1)\\n    acc_cnt += np.sum(p == t[i : i + batch_size])\\n\\nprint(\\\"Accuracy :\\\" + str(float(acc_cnt) / len(x)))\";\n",
       "                var nbb_formatted_code = \"x, t = get_data()\\nnetwork = init_network()\\n\\nbatch_size = 100\\nacc_cnt = 0\\nfor i in range(0, len(x), batch_size):\\n    x_batch = x[i : i + batch_size]\\n    y = forward(network, x_batch)\\n    p = np.argmax(y, axis=1)\\n    acc_cnt += np.sum(p == t[i : i + batch_size])\\n\\nprint(\\\"Accuracy :\\\" + str(float(acc_cnt) / len(x)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100\n",
    "acc_cnt = 0\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i : i + batch_size]\n",
    "    y = forward(network, x_batch)\n",
    "    p = np.argmax(y, axis=1)\n",
    "    acc_cnt += np.sum(p == t[i : i + batch_size])\n",
    "\n",
    "print(\"Accuracy :\" + str(float(acc_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def sum_squared_err(y, t):\\n    return 0.5 * np.sum((y - t) ** 2)\\n\\n\\ndef cross_entropy_err(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n\\n    if t.size == y.size:\\n        t = t.argmax(axis=1)\\n\\n    batch_size = y.shape[0]\\n    delta = 1e-7\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + delta)) / batch_size\";\n",
       "                var nbb_formatted_code = \"def sum_squared_err(y, t):\\n    return 0.5 * np.sum((y - t) ** 2)\\n\\n\\ndef cross_entropy_err(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n\\n    if t.size == y.size:\\n        t = t.argmax(axis=1)\\n\\n    batch_size = y.shape[0]\\n    delta = 1e-7\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + delta)) / batch_size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sum_squared_err(y, t):\n",
    "    return 0.5 * np.sum((y - t) ** 2)\n",
    "\n",
    "\n",
    "def cross_entropy_err(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    delta = 1e-7\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + delta)) / batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load mnist dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\n\\nprint(x_train.shape)\\nprint(t_train.shape)\";\n",
       "                var nbb_formatted_code = \"(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\n\\nprint(x_train.shape)\\nprint(t_train.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"train_size = x_train.shape[0]\\nbatch_size = 10\\nbatch_mask = np.random.choice(train_size, batch_size)\\nx_batch = x_train[batch_mask]\\nt_batch = t_train[batch_mask]\";\n",
       "                var nbb_formatted_code = \"train_size = x_train.shape[0]\\nbatch_size = 10\\nbatch_mask = np.random.choice(train_size, batch_size)\\nx_batch = x_train[batch_mask]\\nt_batch = t_train[batch_mask]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def numerical_diff(f, x):\\n    h = 1e-4\\n    return (f(x + h) - f(x - h)) / (2 * h)\\n\\n\\ndef _numerical_gradient(f, x):\\n    h = 1e-4\\n    grad = np.zeros_like(x)\\n\\n    for id in range(x.size):\\n        tmp_val = x[id]\\n        x[id] = tmp_val + h\\n        fx1 = f(x)\\n\\n        x[id] = tmp_val - h\\n        fx2 = f(x)\\n\\n        grad[id] = (fx1 - fx2) / (2 * h)\\n        x[id] = tmp_val\\n\\n    return grad\\n\\n\\ndef numerical_gradient_2d(f, xs):\\n    if xs.ndim == 1:\\n        return _numerical_gradient(f, xs)\\n    else:\\n        grad = np.zeros_like(xs)\\n        for i, x in enumerate(xs):\\n            grad[i] = _numerical_gradient(f, x)\\n        return grad\";\n",
       "                var nbb_formatted_code = \"def numerical_diff(f, x):\\n    h = 1e-4\\n    return (f(x + h) - f(x - h)) / (2 * h)\\n\\n\\ndef _numerical_gradient(f, x):\\n    h = 1e-4\\n    grad = np.zeros_like(x)\\n\\n    for id in range(x.size):\\n        tmp_val = x[id]\\n        x[id] = tmp_val + h\\n        fx1 = f(x)\\n\\n        x[id] = tmp_val - h\\n        fx2 = f(x)\\n\\n        grad[id] = (fx1 - fx2) / (2 * h)\\n        x[id] = tmp_val\\n\\n    return grad\\n\\n\\ndef numerical_gradient_2d(f, xs):\\n    if xs.ndim == 1:\\n        return _numerical_gradient(f, xs)\\n    else:\\n        grad = np.zeros_like(xs)\\n        for i, x in enumerate(xs):\\n            grad[i] = _numerical_gradient(f, x)\\n        return grad\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "\n",
    "def _numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for id in range(x.size):\n",
    "        tmp_val = x[id]\n",
    "        x[id] = tmp_val + h\n",
    "        fx1 = f(x)\n",
    "\n",
    "        x[id] = tmp_val - h\n",
    "        fx2 = f(x)\n",
    "\n",
    "        grad[id] = (fx1 - fx2) / (2 * h)\n",
    "        x[id] = tmp_val\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def numerical_gradient_2d(f, xs):\n",
    "    if xs.ndim == 1:\n",
    "        return _numerical_gradient(f, xs)\n",
    "    else:\n",
    "        grad = np.zeros_like(xs)\n",
    "        for i, x in enumerate(xs):\n",
    "            grad[i] = _numerical_gradient(f, x)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def gradient_descent(f, init_x, lr=0.01, step_num=100):\\n    x = init_x\\n    for i in range(step_num):\\n        grad = numerical_gradient(f, x)\\n        x -= lr * grad\\n\\n    return x\";\n",
       "                var nbb_formatted_code = \"def gradient_descent(f, init_x, lr=0.01, step_num=100):\\n    x = init_x\\n    for i in range(step_num):\\n        grad = numerical_gradient(f, x)\\n        x -= lr * grad\\n\\n    return x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"class simpleNet:\\n    def __init__(self):\\n        self.W = np.random.randn(2, 3)\\n\\n    def predict(self, x):\\n        return np.dot(x, self.W)\\n\\n    def loss(self, x, t):\\n        prediction = softmax(self.predict(x))\\n        return cross_entropy_err(prediction, t)\";\n",
       "                var nbb_formatted_code = \"class simpleNet:\\n    def __init__(self):\\n        self.W = np.random.randn(2, 3)\\n\\n    def predict(self, x):\\n        return np.dot(x, self.W)\\n\\n    def loss(self, x, t):\\n        prediction = softmax(self.predict(x))\\n        return cross_entropy_err(prediction, t)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        prediction = softmax(self.predict(x))\n",
    "        return cross_entropy_err(prediction, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67595793  0.96955799  1.32669902]\n",
      " [ 0.18469408  0.21010664 -0.5036905 ]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"simple_net = simpleNet()\\nprint(simple_net.W)\";\n",
       "                var nbb_formatted_code = \"simple_net = simpleNet()\\nprint(simple_net.W)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_net = simpleNet()\n",
    "print(simple_net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23935009  0.77083077  0.34269796]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"x = np.array([0.6, 0.9])\\np = simple_net.predict(x)\\nprint(p)\";\n",
       "                var nbb_formatted_code = \"x = np.array([0.6, 0.9])\\np = simple_net.predict(x)\\nprint(p)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = simple_net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"np.argmax(p)\";\n",
       "                var nbb_formatted_code = \"np.argmax(p)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1291873176618032"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"t = np.array([0, 0, 1])\\nsimple_net.loss(x, t)\";\n",
       "                var nbb_formatted_code = \"t = np.array([0, 0, 1])\\nsimple_net.loss(x, t)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1])\n",
    "simple_net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"from operator import itemgetter\\n\\n\\nclass TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        self.params = {\\n            \\\"W1\\\": weight_init_std * np.random.randn(input_size, hidden_size),\\n            \\\"b1\\\": np.zeros(hidden_size),\\n            \\\"W2\\\": weight_init_std * np.random.randn(hidden_size, output_size),\\n            \\\"b2\\\": np.zeros(output_size),\\n        }\\n\\n    def predict(self, x):\\n        W1, W2, b1, b2 = itemgetter(\\\"W1\\\", \\\"W2\\\", \\\"b1\\\", \\\"b2\\\")(self.params)\\n\\n        x = np.dot(x, W1) + b1\\n        x = sigmoid(x)\\n        x = np.dot(x, W2) + b2\\n        return softmax(x)\\n\\n    def loss(self, x, t):\\n        return cross_entropy_err(self.predict(x), t)\\n\\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        t = np.argmax(t, axis=1)\\n\\n        return np.sum(y == t) / float(x.shape[0])\\n\\n    def numerical_gradient(self, x, t):\\n        loss_W = lambda W: self.loss(x, t)\\n\\n        return {\\n            \\\"W1\\\": numerical_gradient_2d(loss_W, self.params[\\\"W1\\\"]),\\n            \\\"b1\\\": numerical_gradient_2d(loss_W, self.params[\\\"b1\\\"]),\\n            \\\"W2\\\": numerical_gradient_2d(loss_W, self.params[\\\"W2\\\"]),\\n            \\\"b2\\\": numerical_gradient_2d(loss_W, self.params[\\\"b2\\\"]),\\n        }\";\n",
       "                var nbb_formatted_code = \"from operator import itemgetter\\n\\n\\nclass TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        self.params = {\\n            \\\"W1\\\": weight_init_std * np.random.randn(input_size, hidden_size),\\n            \\\"b1\\\": np.zeros(hidden_size),\\n            \\\"W2\\\": weight_init_std * np.random.randn(hidden_size, output_size),\\n            \\\"b2\\\": np.zeros(output_size),\\n        }\\n\\n    def predict(self, x):\\n        W1, W2, b1, b2 = itemgetter(\\\"W1\\\", \\\"W2\\\", \\\"b1\\\", \\\"b2\\\")(self.params)\\n\\n        x = np.dot(x, W1) + b1\\n        x = sigmoid(x)\\n        x = np.dot(x, W2) + b2\\n        return softmax(x)\\n\\n    def loss(self, x, t):\\n        return cross_entropy_err(self.predict(x), t)\\n\\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        t = np.argmax(t, axis=1)\\n\\n        return np.sum(y == t) / float(x.shape[0])\\n\\n    def numerical_gradient(self, x, t):\\n        loss_W = lambda W: self.loss(x, t)\\n\\n        return {\\n            \\\"W1\\\": numerical_gradient_2d(loss_W, self.params[\\\"W1\\\"]),\\n            \\\"b1\\\": numerical_gradient_2d(loss_W, self.params[\\\"b1\\\"]),\\n            \\\"W2\\\": numerical_gradient_2d(loss_W, self.params[\\\"W2\\\"]),\\n            \\\"b2\\\": numerical_gradient_2d(loss_W, self.params[\\\"b2\\\"]),\\n        }\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {\n",
    "            \"W1\": weight_init_std * np.random.randn(input_size, hidden_size),\n",
    "            \"b1\": np.zeros(hidden_size),\n",
    "            \"W2\": weight_init_std * np.random.randn(hidden_size, output_size),\n",
    "            \"b2\": np.zeros(output_size),\n",
    "        }\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2, b1, b2 = itemgetter(\"W1\", \"W2\", \"b1\", \"b2\")(self.params)\n",
    "\n",
    "        x = np.dot(x, W1) + b1\n",
    "        x = sigmoid(x)\n",
    "        x = np.dot(x, W2) + b2\n",
    "        return softmax(x)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        return cross_entropy_err(self.predict(x), t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "\n",
    "        return np.sum(y == t) / float(x.shape[0])\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "        return {\n",
    "            \"W1\": numerical_gradient_2d(loss_W, self.params[\"W1\"]),\n",
    "            \"b1\": numerical_gradient_2d(loss_W, self.params[\"b1\"]),\n",
    "            \"W2\": numerical_gradient_2d(loss_W, self.params[\"W2\"]),\n",
    "            \"b2\": numerical_gradient_2d(loss_W, self.params[\"b2\"]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test cc are 0.10441666666666667 0.1028\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\ntrain_loss_list = []\\ntrain_acc_list = []\\ntest_acc_list = []\\niters_num = 1\\ntrain_size = x_train.shape[0]\\nbatch_size = 100\\nlearning_rate = 0.1\\niter_per_epoch = max(train_size / batch_size, 1)\\n\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nfor i in range(iters_num):\\n    batch_mask = np.random.choice(train_size, batch_size)\\n    x_batch = x_train[batch_mask]\\n    t_batch = t_train[batch_mask]\\n\\n    grad = network.numerical_gradient(x_batch, t_batch)\\n    for key in {\\\"W1\\\", \\\"b1\\\", \\\"W2\\\", \\\"b2\\\"}:\\n        network.params[key] -= learning_rate * grad[key]\\n\\n    loss = network.loss(x_batch, t_batch)\\n    train_loss_list.append(loss)\\n\\n    if i % iter_per_epoch == 0:\\n        train_acc = network.accuracy(x_train, t_train)\\n        test_acc = network.accuracy(x_test, t_test)\\n        train_acc_list.append(train_acc)\\n        test_acc_list.append(test_acc)\\n        print(\\\"train acc, test cc are \\\" + str(train_acc) + \\\" \\\" + str(test_acc))\";\n",
       "                var nbb_formatted_code = \"(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\ntrain_loss_list = []\\ntrain_acc_list = []\\ntest_acc_list = []\\niters_num = 1\\ntrain_size = x_train.shape[0]\\nbatch_size = 100\\nlearning_rate = 0.1\\niter_per_epoch = max(train_size / batch_size, 1)\\n\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nfor i in range(iters_num):\\n    batch_mask = np.random.choice(train_size, batch_size)\\n    x_batch = x_train[batch_mask]\\n    t_batch = t_train[batch_mask]\\n\\n    grad = network.numerical_gradient(x_batch, t_batch)\\n    for key in {\\\"W1\\\", \\\"b1\\\", \\\"W2\\\", \\\"b2\\\"}:\\n        network.params[key] -= learning_rate * grad[key]\\n\\n    loss = network.loss(x_batch, t_batch)\\n    train_loss_list.append(loss)\\n\\n    if i % iter_per_epoch == 0:\\n        train_acc = network.accuracy(x_train, t_train)\\n        test_acc = network.accuracy(x_test, t_test)\\n        train_acc_list.append(train_acc)\\n        test_acc_list.append(test_acc)\\n        print(\\\"train acc, test cc are \\\" + str(train_acc) + \\\" \\\" + str(test_acc))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "iters_num = 1\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    for key in {\"W1\", \"b1\", \"W2\", \"b2\"}:\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test cc are \" + str(train_acc) + \" \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Layers for backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"class AddLayer:\\n    def __init__(self):\\n        pass\\n\\n    def forward(self, x, y):\\n        return x + y\\n\\n    def backward(self, dout):\\n        return dout, dout\\n\\n\\nclass MutLayer:\\n    def __init__(self):\\n        self.x = None\\n        self.y = None\\n\\n    def forward(self, x, y):\\n        self.x = x\\n        self.y = y\\n        return x * y\\n\\n    def backward(self, dout):\\n        dx = dout * self.y\\n        dy = dout * self.x\\n\\n        return dx, dy\\n\\n\\nclass ReluLayer:\\n    def __init__(self):\\n        self.mask = None\\n\\n    def forward(self, x):\\n        self.mask = x <= 0\\n        out = x.copy()\\n        out[self.mask] = 0\\n\\n        return out\\n\\n    def backward(self, dout):\\n        dout[self.mask] = 0\\n        return dout\\n\\n\\nclass SigmoidLayer:\\n    def __init__(self):\\n        self.out = None\\n\\n    def forward(self, x):\\n        self.out = 1 / (1 + np.exp(-x))\\n        return self.out\\n\\n    def backward(self, dout):\\n        return dout * (1.0 - self.out) * self.out\\n\\n\\nclass AffineLayer:\\n    def __init__(self, W, b):\\n        self.W = W\\n        self.b = b\\n        self.x = None\\n        self.dW = None\\n        self.db = None\\n\\n    def forward(self, x):\\n        self.x = x\\n        return np.dot(x, self.W) + self.b\\n\\n    def backward(self, dout):\\n        self.dW = np.dot(self.x.T, dout)\\n        self.db = np.sum(dout, axis=0)\\n\\n        return np.dot(dout, self.W.T)\\n\\n\\nclass SoftmaxWithLossLayer:\\n    def __init__(self):\\n        self.loss = None\\n        self.y = None\\n        self.t = None\\n\\n    def forward(self, x, t):\\n        self.t = t\\n        self.y = softmax(x)\\n        self.loss = cross_entropy_err(self.y, self.t)\\n\\n        return self.loss\\n\\n    def backward(self, dout=1):\\n        batch_size = self.t.shape[0]\\n        return (self.y - self.t) / batch_size\";\n",
       "                var nbb_formatted_code = \"class AddLayer:\\n    def __init__(self):\\n        pass\\n\\n    def forward(self, x, y):\\n        return x + y\\n\\n    def backward(self, dout):\\n        return dout, dout\\n\\n\\nclass MutLayer:\\n    def __init__(self):\\n        self.x = None\\n        self.y = None\\n\\n    def forward(self, x, y):\\n        self.x = x\\n        self.y = y\\n        return x * y\\n\\n    def backward(self, dout):\\n        dx = dout * self.y\\n        dy = dout * self.x\\n\\n        return dx, dy\\n\\n\\nclass ReluLayer:\\n    def __init__(self):\\n        self.mask = None\\n\\n    def forward(self, x):\\n        self.mask = x <= 0\\n        out = x.copy()\\n        out[self.mask] = 0\\n\\n        return out\\n\\n    def backward(self, dout):\\n        dout[self.mask] = 0\\n        return dout\\n\\n\\nclass SigmoidLayer:\\n    def __init__(self):\\n        self.out = None\\n\\n    def forward(self, x):\\n        self.out = 1 / (1 + np.exp(-x))\\n        return self.out\\n\\n    def backward(self, dout):\\n        return dout * (1.0 - self.out) * self.out\\n\\n\\nclass AffineLayer:\\n    def __init__(self, W, b):\\n        self.W = W\\n        self.b = b\\n        self.x = None\\n        self.dW = None\\n        self.db = None\\n\\n    def forward(self, x):\\n        self.x = x\\n        return np.dot(x, self.W) + self.b\\n\\n    def backward(self, dout):\\n        self.dW = np.dot(self.x.T, dout)\\n        self.db = np.sum(dout, axis=0)\\n\\n        return np.dot(dout, self.W.T)\\n\\n\\nclass SoftmaxWithLossLayer:\\n    def __init__(self):\\n        self.loss = None\\n        self.y = None\\n        self.t = None\\n\\n    def forward(self, x, t):\\n        self.t = t\\n        self.y = softmax(x)\\n        self.loss = cross_entropy_err(self.y, self.t)\\n\\n        return self.loss\\n\\n    def backward(self, dout=1):\\n        batch_size = self.t.shape[0]\\n        return (self.y - self.t) / batch_size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return x + y\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout, dout\n",
    "\n",
    "\n",
    "class MutLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return x * y\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy\n",
    "\n",
    "\n",
    "class ReluLayer:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = x <= 0\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        return dout\n",
    "\n",
    "\n",
    "class SigmoidLayer:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = 1 / (1 + np.exp(-x))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * (1.0 - self.out) * self.out\n",
    "\n",
    "\n",
    "class AffineLayer:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.W) + self.b\n",
    "\n",
    "    def backward(self, dout):\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "\n",
    "        return np.dot(dout, self.W.T)\n",
    "\n",
    "\n",
    "class SoftmaxWithLossLayer:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_err(self.y, self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        return (self.y - self.t) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twolayer network with Graph classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"from collections import OrderedDict\\n\\n\\nclass TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        self.params = {\\n            \\\"W1\\\": weight_init_std * np.random.randn(input_size, hidden_size),\\n            \\\"b1\\\": np.zeros(hidden_size),\\n            \\\"W2\\\": weight_init_std * np.random.randn(hidden_size, output_size),\\n            \\\"b2\\\": np.zeros(output_size),\\n        }\\n\\n        self.layers = OrderedDict(\\n            {\\n                \\\"Affine1\\\": AffineLayer(self.params[\\\"W1\\\"], self.params[\\\"b1\\\"]),\\n                \\\"Relu1\\\": ReluLayer(),\\n                \\\"Affine2\\\": AffineLayer(self.params[\\\"W2\\\"], self.params[\\\"b2\\\"]),\\n            }\\n        )\\n        self.lastLayer = SoftmaxWithLossLayer()\\n\\n    def predict(self, x):\\n        for layer in self.layers.values():\\n            x = layer.forward(x)\\n        return x\\n\\n    def loss(self, x, t):\\n        y = self.predict(x)\\n        return self.lastLayer.forward(y, t)\\n\\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        if t.ndim != 1:\\n            t = np.argmax(t, axis=1)\\n\\n        return np.sum(y == t) / float(x.shape[0])\\n\\n    def gradient(self, x, t):\\n        # Forward\\n        self.loss(x, t)\\n\\n        # Backward\\n        dout = 1\\n        dout = self.lastLayer.backward(dout)\\n\\n        layers = list(self.layers.values())\\n        layers.reverse()\\n        for layer in layers:\\n            dout = layer.backward(dout)\\n\\n        return {\\n            \\\"W1\\\": self.layers[\\\"Affine1\\\"].dW,\\n            \\\"b1\\\": self.layers[\\\"Affine1\\\"].db,\\n            \\\"W2\\\": self.layers[\\\"Affine2\\\"].dW,\\n            \\\"b2\\\": self.layers[\\\"Affine2\\\"].db,\\n        }\";\n",
       "                var nbb_formatted_code = \"from collections import OrderedDict\\n\\n\\nclass TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\\n        self.params = {\\n            \\\"W1\\\": weight_init_std * np.random.randn(input_size, hidden_size),\\n            \\\"b1\\\": np.zeros(hidden_size),\\n            \\\"W2\\\": weight_init_std * np.random.randn(hidden_size, output_size),\\n            \\\"b2\\\": np.zeros(output_size),\\n        }\\n\\n        self.layers = OrderedDict(\\n            {\\n                \\\"Affine1\\\": AffineLayer(self.params[\\\"W1\\\"], self.params[\\\"b1\\\"]),\\n                \\\"Relu1\\\": ReluLayer(),\\n                \\\"Affine2\\\": AffineLayer(self.params[\\\"W2\\\"], self.params[\\\"b2\\\"]),\\n            }\\n        )\\n        self.lastLayer = SoftmaxWithLossLayer()\\n\\n    def predict(self, x):\\n        for layer in self.layers.values():\\n            x = layer.forward(x)\\n        return x\\n\\n    def loss(self, x, t):\\n        y = self.predict(x)\\n        return self.lastLayer.forward(y, t)\\n\\n    def accuracy(self, x, t):\\n        y = self.predict(x)\\n        y = np.argmax(y, axis=1)\\n        if t.ndim != 1:\\n            t = np.argmax(t, axis=1)\\n\\n        return np.sum(y == t) / float(x.shape[0])\\n\\n    def gradient(self, x, t):\\n        # Forward\\n        self.loss(x, t)\\n\\n        # Backward\\n        dout = 1\\n        dout = self.lastLayer.backward(dout)\\n\\n        layers = list(self.layers.values())\\n        layers.reverse()\\n        for layer in layers:\\n            dout = layer.backward(dout)\\n\\n        return {\\n            \\\"W1\\\": self.layers[\\\"Affine1\\\"].dW,\\n            \\\"b1\\\": self.layers[\\\"Affine1\\\"].db,\\n            \\\"W2\\\": self.layers[\\\"Affine2\\\"].dW,\\n            \\\"b2\\\": self.layers[\\\"Affine2\\\"].db,\\n        }\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {\n",
    "            \"W1\": weight_init_std * np.random.randn(input_size, hidden_size),\n",
    "            \"b1\": np.zeros(hidden_size),\n",
    "            \"W2\": weight_init_std * np.random.randn(hidden_size, output_size),\n",
    "            \"b2\": np.zeros(output_size),\n",
    "        }\n",
    "\n",
    "        self.layers = OrderedDict(\n",
    "            {\n",
    "                \"Affine1\": AffineLayer(self.params[\"W1\"], self.params[\"b1\"]),\n",
    "                \"Relu1\": ReluLayer(),\n",
    "                \"Affine2\": AffineLayer(self.params[\"W2\"], self.params[\"b2\"]),\n",
    "            }\n",
    "        )\n",
    "        self.lastLayer = SoftmaxWithLossLayer()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "\n",
    "        return np.sum(y == t) / float(x.shape[0])\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # Forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # Backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        return {\n",
    "            \"W1\": self.layers[\"Affine1\"].dW,\n",
    "            \"b1\": self.layers[\"Affine1\"].db,\n",
    "            \"W2\": self.layers[\"Affine2\"].dW,\n",
    "            \"b2\": self.layers[\"Affine2\"].db,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc are 0.11823333333333333 0.1253\n",
      "train acc, test acc are 0.09871666666666666 0.098\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\ntrain_loss_list = []\\ntrain_acc_list = []\\ntest_acc_list = []\\niters_num = 1000\\ntrain_size = x_train.shape[0]\\nbatch_size = 100\\nlearning_rate = 0.1\\niter_per_epoch = max(train_size / batch_size, 1)\\n\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nfor i in range(iters_num):\\n    batch_mask = np.random.choice(train_size, batch_size)\\n    x_batch = x_train[batch_mask]\\n    t_batch = t_train[batch_mask]\\n\\n    grad = network.gradient(x_batch, t_batch)\\n    for key in {\\\"W1\\\", \\\"b1\\\", \\\"W2\\\", \\\"b2\\\"}:\\n        network.params[key] -= learning_rate * grad[key]\\n\\n    loss = network.loss(x_batch, t_batch)\\n    train_loss_list.append(loss)\\n\\n    if i % iter_per_epoch == 0:\\n        train_acc = network.accuracy(x_train, t_train)\\n        test_acc = network.accuracy(x_test, t_test)\\n        train_acc_list.append(train_acc)\\n        test_acc_list.append(test_acc)\\n        print(\\\"train acc, test acc are \\\" + str(train_acc) + \\\" \\\" + str(test_acc))\";\n",
       "                var nbb_formatted_code = \"(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\\ntrain_loss_list = []\\ntrain_acc_list = []\\ntest_acc_list = []\\niters_num = 1000\\ntrain_size = x_train.shape[0]\\nbatch_size = 100\\nlearning_rate = 0.1\\niter_per_epoch = max(train_size / batch_size, 1)\\n\\n\\nnetwork = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\\n\\nfor i in range(iters_num):\\n    batch_mask = np.random.choice(train_size, batch_size)\\n    x_batch = x_train[batch_mask]\\n    t_batch = t_train[batch_mask]\\n\\n    grad = network.gradient(x_batch, t_batch)\\n    for key in {\\\"W1\\\", \\\"b1\\\", \\\"W2\\\", \\\"b2\\\"}:\\n        network.params[key] -= learning_rate * grad[key]\\n\\n    loss = network.loss(x_batch, t_batch)\\n    train_loss_list.append(loss)\\n\\n    if i % iter_per_epoch == 0:\\n        train_acc = network.accuracy(x_train, t_train)\\n        test_acc = network.accuracy(x_test, t_test)\\n        train_acc_list.append(train_acc)\\n        test_acc_list.append(test_acc)\\n        print(\\\"train acc, test acc are \\\" + str(train_acc) + \\\" \\\" + str(test_acc))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    for key in {\"W1\", \"b1\", \"W2\", \"b2\"}:\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc are \" + str(train_acc) + \" \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to update hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"class SGD:\\n    def __init__(self, lr=0.01):\\n        self.lr = lr\\n\\n    def update(self, params, grads):\\n        for key in params.keys():\\n            params[key] -= self.lr * grads[key]\\n\\n\\nclass Momentum:\\n    def __init__(self, lr=0.01, momentum=0.9):\\n        self.lr = lr\\n        self.momentum = momentum\\n        self.v = None\\n\\n    def update(self, params, grads):\\n        if self.v is None:\\n            self.v = {}\\n            for key, valu in params.items():\\n                self.v[key] = np.zeros_like(val)\\n\\n        for key in params.keys():\\n            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\\n            params[key] += self.v[key]\\n\\n\\nclass AdaGrad:\\n    def __init_(self, lr=0.01):\\n        self.lr = lr\\n        self.h = None\\n\\n    def update(self, params, grads):\\n        if self.h is None:\\n            self.h = {}\\n            for key, val in params.items():\\n                self.h[key] = np.zeros_like(val)\\n\\n        for key in params.keys():\\n            self.h[key] += grads[key] * grads[key]\\n            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\";\n",
       "                var nbb_formatted_code = \"class SGD:\\n    def __init__(self, lr=0.01):\\n        self.lr = lr\\n\\n    def update(self, params, grads):\\n        for key in params.keys():\\n            params[key] -= self.lr * grads[key]\\n\\n\\nclass Momentum:\\n    def __init__(self, lr=0.01, momentum=0.9):\\n        self.lr = lr\\n        self.momentum = momentum\\n        self.v = None\\n\\n    def update(self, params, grads):\\n        if self.v is None:\\n            self.v = {}\\n            for key, valu in params.items():\\n                self.v[key] = np.zeros_like(val)\\n\\n        for key in params.keys():\\n            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\\n            params[key] += self.v[key]\\n\\n\\nclass AdaGrad:\\n    def __init_(self, lr=0.01):\\n        self.lr = lr\\n        self.h = None\\n\\n    def update(self, params, grads):\\n        if self.h is None:\\n            self.h = {}\\n            for key, val in params.items():\\n                self.h[key] = np.zeros_like(val)\\n\\n        for key in params.keys():\\n            self.h[key] += grads[key] * grads[key]\\n            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]\n",
    "\n",
    "\n",
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, valu in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]\n",
    "\n",
    "\n",
    "class AdaGrad:\n",
    "    def __init_(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\\n    N, C, H, W = input_shape\\n    out_h = (H + 2 * pad - filter_h) // stride + 1\\n    out_w = (W + 2 * pad - filter_w) // stride + 1\\n    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(\\n        0, 3, 4, 5, 1, 2\\n    )\\n    img = np.zeros((N, C, H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))\\n    for y in range(filter_h):\\n        y_max = y + stride * out_h\\n        for x in range(filter_w):\\n            x_max = x + stride * out_w\\n            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\\n\\n    return img[:, :, pad : H + pad, pad : W + pad]\\n\\n\\ndef im2col(input_data, filter_h, filter_w, stride=1, pad=0):\\n    N, C, H, W = input_data.shape\\n    out_h = (H + 2 * pad - filter_h) // stride + 1\\n    out_w = (W + 2 * pad - filter_w) // stride + 1\\n\\n    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], \\\"constant\\\")\\n    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\\n\\n    for y in range(filter_h):\\n        y_max = y + stride * out_h\\n        for x in range(filter_w):\\n            x_max = x + stride * out_w\\n            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\\n\\n    return col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\";\n",
       "                var nbb_formatted_code = \"def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\\n    N, C, H, W = input_shape\\n    out_h = (H + 2 * pad - filter_h) // stride + 1\\n    out_w = (W + 2 * pad - filter_w) // stride + 1\\n    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(\\n        0, 3, 4, 5, 1, 2\\n    )\\n    img = np.zeros((N, C, H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))\\n    for y in range(filter_h):\\n        y_max = y + stride * out_h\\n        for x in range(filter_w):\\n            x_max = x + stride * out_w\\n            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\\n\\n    return img[:, :, pad : H + pad, pad : W + pad]\\n\\n\\ndef im2col(input_data, filter_h, filter_w, stride=1, pad=0):\\n    N, C, H, W = input_data.shape\\n    out_h = (H + 2 * pad - filter_h) // stride + 1\\n    out_w = (W + 2 * pad - filter_w) // stride + 1\\n\\n    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], \\\"constant\\\")\\n    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\\n\\n    for y in range(filter_h):\\n        y_max = y + stride * out_h\\n        for x in range(filter_w):\\n            x_max = x + stride * out_w\\n            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\\n\\n    return col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2 * pad - filter_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - filter_w) // stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(\n",
    "        0, 3, 4, 5, 1, 2\n",
    "    )\n",
    "    img = np.zeros((N, C, H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride * out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride * out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad : H + pad, pad : W + pad]\n",
    "\n",
    "\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2 * pad - filter_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - filter_w) // stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], \"constant\")\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride * out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride * out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    return col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 75)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"x1 = np.random.rand(10, 3, 7, 7)\\ncol1 = im2col(x1, 5, 5, stride=1, pad=0)\\ncol1.shape\";\n",
       "                var nbb_formatted_code = \"x1 = np.random.rand(10, 3, 7, 7)\\ncol1 = im2col(x1, 5, 5, stride=1, pad=0)\\ncol1.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.random.rand(10, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "col1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"class Convolution:\\n    def __init__(self, W, b, stride=1, pad=0):\\n        self.W = W\\n        self.b = b\\n        self.stride = stride\\n        self.pad = pad\\n\\n        self.x = None\\n        self.col = None\\n        self.col_W = None\\n\\n        self.dW = None\\n        self.db = None\\n\\n    def forward(self, x):\\n        FN, C, FH, FW = self.W.shape\\n        N, C, H, W = x.shape\\n\\n        self.x = x\\n        self.col = im2col(x, FH, FW, self.stride, self.pad)\\n        self.col_W = self.W.reshape(FN, -1).T\\n\\n        out = np.dot(self.col, self.col_W) + self.b\\n        out_h = int(1 + (H + 2 * self.pad - FH) / self.stride)\\n        out_w = int(1 + (W + 2 * self.pad - FW) / self.stride)\\n\\n        return out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\\n\\n    def backward(self, dout):\\n        FN, C, FH, FW = self.W.shape\\n        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)\\n\\n        self.db = np.sum(dout, axis=0)\\n        self.dW = np.dot(self.col.T, dout)\\n        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\\n\\n        dcol = np.dot(dout, self.col_W.T)\\n\\n        return col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\";\n",
       "                var nbb_formatted_code = \"class Convolution:\\n    def __init__(self, W, b, stride=1, pad=0):\\n        self.W = W\\n        self.b = b\\n        self.stride = stride\\n        self.pad = pad\\n\\n        self.x = None\\n        self.col = None\\n        self.col_W = None\\n\\n        self.dW = None\\n        self.db = None\\n\\n    def forward(self, x):\\n        FN, C, FH, FW = self.W.shape\\n        N, C, H, W = x.shape\\n\\n        self.x = x\\n        self.col = im2col(x, FH, FW, self.stride, self.pad)\\n        self.col_W = self.W.reshape(FN, -1).T\\n\\n        out = np.dot(self.col, self.col_W) + self.b\\n        out_h = int(1 + (H + 2 * self.pad - FH) / self.stride)\\n        out_w = int(1 + (W + 2 * self.pad - FW) / self.stride)\\n\\n        return out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\\n\\n    def backward(self, dout):\\n        FN, C, FH, FW = self.W.shape\\n        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)\\n\\n        self.db = np.sum(dout, axis=0)\\n        self.dW = np.dot(self.col.T, dout)\\n        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\\n\\n        dcol = np.dot(dout, self.col_W.T)\\n\\n        return col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "        self.x = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "\n",
    "        self.x = x\n",
    "        self.col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        self.col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(self.col, self.col_W) + self.b\n",
    "        out_h = int(1 + (H + 2 * self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2 * self.pad - FW) / self.stride)\n",
    "\n",
    "        return out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "\n",
    "        return col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"class Pooling:\\n    def __init__(self, pool_h, pool_w, stride=2, pad=0):\\n        self.pool_h = pool_h\\n        self.pool_w = pool_w\\n        self.stride = stride\\n        self.pad = pad\\n\\n        self.x = None\\n        self.arg_max = None\\n\\n    def forward(self, x):\\n        N, C, H, W = x.shape\\n        out_h = int(1 + (H - self.pool_h) / self.stride)\\n        out_w = int(1 + (W - self.pool_w) / self.stride)\\n\\n        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\\n        col = col.reshape(-1, self.pool_h * self.pool_w)\\n\\n        self.x = x\\n        self.arg_max = np.argmax(col, axis=1)\\n\\n        out = np.max(col, axis=1)\\n\\n        return out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\\n\\n    def backward(self, dout):\\n        dout = dout.transpose(0, 2, 3, 1)\\n\\n        pool_size = self.pool_h * self.pool_w\\n        dmax = np.zeros((dout.size, pool_size))\\n        dmax[np.arange(self.argmax.size), self.arg_max.flatten()] = dout.flatten()\\n        dmax = dmax.reshape(dout.shape * (pool_size,))\\n\\n        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\\n\\n        return col2im(\\n            dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad\\n        )\";\n",
       "                var nbb_formatted_code = \"class Pooling:\\n    def __init__(self, pool_h, pool_w, stride=2, pad=0):\\n        self.pool_h = pool_h\\n        self.pool_w = pool_w\\n        self.stride = stride\\n        self.pad = pad\\n\\n        self.x = None\\n        self.arg_max = None\\n\\n    def forward(self, x):\\n        N, C, H, W = x.shape\\n        out_h = int(1 + (H - self.pool_h) / self.stride)\\n        out_w = int(1 + (W - self.pool_w) / self.stride)\\n\\n        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\\n        col = col.reshape(-1, self.pool_h * self.pool_w)\\n\\n        self.x = x\\n        self.arg_max = np.argmax(col, axis=1)\\n\\n        out = np.max(col, axis=1)\\n\\n        return out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\\n\\n    def backward(self, dout):\\n        dout = dout.transpose(0, 2, 3, 1)\\n\\n        pool_size = self.pool_h * self.pool_w\\n        dmax = np.zeros((dout.size, pool_size))\\n        dmax[np.arange(self.argmax.size), self.arg_max.flatten()] = dout.flatten()\\n        dmax = dmax.reshape(dout.shape * (pool_size,))\\n\\n        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\\n\\n        return col2im(\\n            dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = np.argmax(col, axis=1)\n",
    "\n",
    "        out = np.max(col, axis=1)\n",
    "\n",
    "        return out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "\n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.argmax.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape * (pool_size,))\n",
    "\n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "\n",
    "        return col2im(\n",
    "            dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"class SimpleConvNet:\\n    def __init__(\\n        self,\\n        input_dim=(1, 28, 28),\\n        conv_param={\\\"filter_num\\\": 30, \\\"filter_size\\\": 5, \\\"pad\\\": 0, \\\"stride\\\": 1},\\n        hidden_size=100,\\n        output_size=10,\\n        weight_init_std=0.01,\\n    ):\\n        filter_num, filter_size, filter_pad, filter_stride = itemgetter(\\n            \\\"filter_num\\\", \\\"filter_size\\\", \\\"pad\\\", \\\"stride\\\"\\n        )(conv_param)\\n        input_size = input_dim[1]\\n        conv_output_size = (\\n            input_size - filter_size + 2 * filter_pad\\n        ) / filter_stride + 1\\n        pool_output_size = int(\\n            filter_num * (conv_output_size / 2) * (conv_output_size / 2)\\n        )\\n\\n        # Init parameters\\n        self.params = {\\n            \\\"W1\\\": weight_init_std\\n            * np.random.randn(filter_num, input_dim[0], filter_size, filter_size),\\n            \\\"b1\\\": np.zeros(filter_num),\\n            \\\"W2\\\": weight_init_std * np.random.randn(pool_output_size, hidden_size),\\n            \\\"b2\\\": np.zeros(hidden_size),\\n            \\\"W3\\\": weight_init_std * np.random.randn(hidden_size, output_size),\\n            \\\"b3\\\": np.zeros(output_size),\\n        }\\n\\n        # Layers\\n        self.layers = OrderedDict(\\n            {\\n                \\\"Conv1\\\": Convolution(\\n                    self.params[\\\"W1\\\"],\\n                    self.params[\\\"b1\\\"],\\n                    conv_params[\\\"stride\\\"],\\n                    conv_param[\\\"pad\\\"],\\n                ),\\n                \\\"Relu1\\\": ReluLayer(),\\n                \\\"Pool1\\\": Pooling(pool_h=2, pool_w=2, stride=2),\\n                \\\"Affine1\\\": AffineLayer(self.params[\\\"W2\\\"].self.params[\\\"b2\\\"]),\\n                \\\"Relu2\\\": ReluLayer(),\\n                \\\"Affine2\\\": AffineLayer(self.params[\\\"W3\\\"], self.params[\\\"b3\\\"]),\\n            }\\n        )\\n\\n        self.last_layer = SoftmaxWithLossLayer()\\n\\n    def predict(self, x):\\n        for l in self.layers.values():\\n            x = l.forward(x)\\n        return x\\n\\n    def loss(self, x, t):\\n        return self.last_layer.forward(self.predict(x), t)\\n\\n    def accuracy(self, x, t, batch_size=100):\\n        if t.ndim != 1:\\n            t = np.argmax(t, axis=1)\\n\\n        acc = 0.0\\n        for i in range(int(x.shape[0] / batch_size)):\\n            tx = x[i * batch_size : (i + 1) * batch_size]\\n            tt = t[i * batch_size : (i + 1) * batch_size]\\n            y = self.predict(tx)\\n            y = np.argmax(y, axis=1)\\n            acc += np.sum(y == tt)\\n\\n        return acc / x.shape[0]\\n\\n    def numerical_gradient(self, x, t):\\n        loss_w = lambda w: self.loss(x, t)\\n\\n        grads = {}\\n        for idx in (1, 2, 3):\\n            grads[\\\"W\\\" + str(idx)] = numerical_gradient(\\n                loss_w, self.params[\\\"W\\\" + str(idx)]\\n            )\\n            grads[\\\"b\\\" + str(idx)] = numerical_gradient(\\n                loss_w, self.params[\\\"b\\\" + str(idx)]\\n            )\\n\\n        return grads\\n\\n    def gradient(self, x, t):\\n        # Forward\\n        self.loss(x, t)\\n\\n        # Backward\\n        dout = 1\\n        dout = self.last_layer.backward(dout)\\n\\n        layers = list(self.layers.values())\\n        layers.reverse()\\n        for l in layers:\\n            dout = l.backward(dout)\\n\\n        return {\\n            \\\"W1\\\": self.layers[\\\"Conv1\\\"].dW,\\n            \\\"b1\\\": self.layers[\\\"Conv1\\\"].db,\\n            \\\"W2\\\": self.layers[\\\"Affine1\\\"].dW,\\n            \\\"b2\\\": self.layers[\\\"Affine1\\\"].db,\\n            \\\"W3\\\": self.layers[\\\"Affine2\\\"].dW,\\n            \\\"b3\\\": self.layers[\\\"Affine2\\\"].db,\\n        }\\n\\n    def save_params(self, file_name=\\\"params.pkl\\\"):\\n        params = {}\\n        for key, val in self.params.items():\\n            params[key] = val\\n        with open(file_name, \\\"wb\\\") as f:\\n            pickle.dump(params, f)\\n\\n    def load_params(self, file_name=\\\"params.pkl\\\"):\\n        with open(file_name, \\\"rb\\\") as f:\\n            params = pickle.load(f)\\n\\n        for key, val in params.items():\\n            self.params[key] = val\\n        for i, key in enumerate([\\\"Conv1\\\", \\\"Affine1\\\", \\\"Affine2\\\"]):\\n            self.layers[key].W = self.params[\\\"W\\\" + str(i + 1)]\\n            self.layers[key].b = self.params[\\\"b\\\" + str(i + 1)]\";\n",
       "                var nbb_formatted_code = \"class SimpleConvNet:\\n    def __init__(\\n        self,\\n        input_dim=(1, 28, 28),\\n        conv_param={\\\"filter_num\\\": 30, \\\"filter_size\\\": 5, \\\"pad\\\": 0, \\\"stride\\\": 1},\\n        hidden_size=100,\\n        output_size=10,\\n        weight_init_std=0.01,\\n    ):\\n        filter_num, filter_size, filter_pad, filter_stride = itemgetter(\\n            \\\"filter_num\\\", \\\"filter_size\\\", \\\"pad\\\", \\\"stride\\\"\\n        )(conv_param)\\n        input_size = input_dim[1]\\n        conv_output_size = (\\n            input_size - filter_size + 2 * filter_pad\\n        ) / filter_stride + 1\\n        pool_output_size = int(\\n            filter_num * (conv_output_size / 2) * (conv_output_size / 2)\\n        )\\n\\n        # Init parameters\\n        self.params = {\\n            \\\"W1\\\": weight_init_std\\n            * np.random.randn(filter_num, input_dim[0], filter_size, filter_size),\\n            \\\"b1\\\": np.zeros(filter_num),\\n            \\\"W2\\\": weight_init_std * np.random.randn(pool_output_size, hidden_size),\\n            \\\"b2\\\": np.zeros(hidden_size),\\n            \\\"W3\\\": weight_init_std * np.random.randn(hidden_size, output_size),\\n            \\\"b3\\\": np.zeros(output_size),\\n        }\\n\\n        # Layers\\n        self.layers = OrderedDict(\\n            {\\n                \\\"Conv1\\\": Convolution(\\n                    self.params[\\\"W1\\\"],\\n                    self.params[\\\"b1\\\"],\\n                    conv_params[\\\"stride\\\"],\\n                    conv_param[\\\"pad\\\"],\\n                ),\\n                \\\"Relu1\\\": ReluLayer(),\\n                \\\"Pool1\\\": Pooling(pool_h=2, pool_w=2, stride=2),\\n                \\\"Affine1\\\": AffineLayer(self.params[\\\"W2\\\"].self.params[\\\"b2\\\"]),\\n                \\\"Relu2\\\": ReluLayer(),\\n                \\\"Affine2\\\": AffineLayer(self.params[\\\"W3\\\"], self.params[\\\"b3\\\"]),\\n            }\\n        )\\n\\n        self.last_layer = SoftmaxWithLossLayer()\\n\\n    def predict(self, x):\\n        for l in self.layers.values():\\n            x = l.forward(x)\\n        return x\\n\\n    def loss(self, x, t):\\n        return self.last_layer.forward(self.predict(x), t)\\n\\n    def accuracy(self, x, t, batch_size=100):\\n        if t.ndim != 1:\\n            t = np.argmax(t, axis=1)\\n\\n        acc = 0.0\\n        for i in range(int(x.shape[0] / batch_size)):\\n            tx = x[i * batch_size : (i + 1) * batch_size]\\n            tt = t[i * batch_size : (i + 1) * batch_size]\\n            y = self.predict(tx)\\n            y = np.argmax(y, axis=1)\\n            acc += np.sum(y == tt)\\n\\n        return acc / x.shape[0]\\n\\n    def numerical_gradient(self, x, t):\\n        loss_w = lambda w: self.loss(x, t)\\n\\n        grads = {}\\n        for idx in (1, 2, 3):\\n            grads[\\\"W\\\" + str(idx)] = numerical_gradient(\\n                loss_w, self.params[\\\"W\\\" + str(idx)]\\n            )\\n            grads[\\\"b\\\" + str(idx)] = numerical_gradient(\\n                loss_w, self.params[\\\"b\\\" + str(idx)]\\n            )\\n\\n        return grads\\n\\n    def gradient(self, x, t):\\n        # Forward\\n        self.loss(x, t)\\n\\n        # Backward\\n        dout = 1\\n        dout = self.last_layer.backward(dout)\\n\\n        layers = list(self.layers.values())\\n        layers.reverse()\\n        for l in layers:\\n            dout = l.backward(dout)\\n\\n        return {\\n            \\\"W1\\\": self.layers[\\\"Conv1\\\"].dW,\\n            \\\"b1\\\": self.layers[\\\"Conv1\\\"].db,\\n            \\\"W2\\\": self.layers[\\\"Affine1\\\"].dW,\\n            \\\"b2\\\": self.layers[\\\"Affine1\\\"].db,\\n            \\\"W3\\\": self.layers[\\\"Affine2\\\"].dW,\\n            \\\"b3\\\": self.layers[\\\"Affine2\\\"].db,\\n        }\\n\\n    def save_params(self, file_name=\\\"params.pkl\\\"):\\n        params = {}\\n        for key, val in self.params.items():\\n            params[key] = val\\n        with open(file_name, \\\"wb\\\") as f:\\n            pickle.dump(params, f)\\n\\n    def load_params(self, file_name=\\\"params.pkl\\\"):\\n        with open(file_name, \\\"rb\\\") as f:\\n            params = pickle.load(f)\\n\\n        for key, val in params.items():\\n            self.params[key] = val\\n        for i, key in enumerate([\\\"Conv1\\\", \\\"Affine1\\\", \\\"Affine2\\\"]):\\n            self.layers[key].W = self.params[\\\"W\\\" + str(i + 1)]\\n            self.layers[key].b = self.params[\\\"b\\\" + str(i + 1)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=(1, 28, 28),\n",
    "        conv_param={\"filter_num\": 30, \"filter_size\": 5, \"pad\": 0, \"stride\": 1},\n",
    "        hidden_size=100,\n",
    "        output_size=10,\n",
    "        weight_init_std=0.01,\n",
    "    ):\n",
    "        filter_num, filter_size, filter_pad, filter_stride = itemgetter(\n",
    "            \"filter_num\", \"filter_size\", \"pad\", \"stride\"\n",
    "        )(conv_param)\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (\n",
    "            input_size - filter_size + 2 * filter_pad\n",
    "        ) / filter_stride + 1\n",
    "        pool_output_size = int(\n",
    "            filter_num * (conv_output_size / 2) * (conv_output_size / 2)\n",
    "        )\n",
    "\n",
    "        # Init parameters\n",
    "        self.params = {\n",
    "            \"W1\": weight_init_std\n",
    "            * np.random.randn(filter_num, input_dim[0], filter_size, filter_size),\n",
    "            \"b1\": np.zeros(filter_num),\n",
    "            \"W2\": weight_init_std * np.random.randn(pool_output_size, hidden_size),\n",
    "            \"b2\": np.zeros(hidden_size),\n",
    "            \"W3\": weight_init_std * np.random.randn(hidden_size, output_size),\n",
    "            \"b3\": np.zeros(output_size),\n",
    "        }\n",
    "\n",
    "        # Layers\n",
    "        self.layers = OrderedDict(\n",
    "            {\n",
    "                \"Conv1\": Convolution(\n",
    "                    self.params[\"W1\"],\n",
    "                    self.params[\"b1\"],\n",
    "                    conv_params[\"stride\"],\n",
    "                    conv_param[\"pad\"],\n",
    "                ),\n",
    "                \"Relu1\": ReluLayer(),\n",
    "                \"Pool1\": Pooling(pool_h=2, pool_w=2, stride=2),\n",
    "                \"Affine1\": AffineLayer(self.params[\"W2\"].self.params[\"b2\"]),\n",
    "                \"Relu2\": ReluLayer(),\n",
    "                \"Affine2\": AffineLayer(self.params[\"W3\"], self.params[\"b3\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.last_layer = SoftmaxWithLossLayer()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for l in self.layers.values():\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        return self.last_layer.forward(self.predict(x), t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i * batch_size : (i + 1) * batch_size]\n",
    "            tt = t[i * batch_size : (i + 1) * batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads[\"W\" + str(idx)] = numerical_gradient(\n",
    "                loss_w, self.params[\"W\" + str(idx)]\n",
    "            )\n",
    "            grads[\"b\" + str(idx)] = numerical_gradient(\n",
    "                loss_w, self.params[\"b\" + str(idx)]\n",
    "            )\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # Forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # Backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for l in layers:\n",
    "            dout = l.backward(dout)\n",
    "\n",
    "        return {\n",
    "            \"W1\": self.layers[\"Conv1\"].dW,\n",
    "            \"b1\": self.layers[\"Conv1\"].db,\n",
    "            \"W2\": self.layers[\"Affine1\"].dW,\n",
    "            \"b2\": self.layers[\"Affine1\"].db,\n",
    "            \"W3\": self.layers[\"Affine2\"].dW,\n",
    "            \"b3\": self.layers[\"Affine2\"].db,\n",
    "        }\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "        for i, key in enumerate([\"Conv1\", \"Affine1\", \"Affine2\"]):\n",
    "            self.layers[key].W = self.params[\"W\" + str(i + 1)]\n",
    "            self.layers[key].b = self.params[\"b\" + str(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "564a3161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "328be07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 90;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d113e85",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "56ff1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 91;\n",
       "                var nbb_unformatted_code = \"def sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n\\ndef softmax(x):\\n    if x.ndim == 2:\\n        x = x - x.max(axis=1, keepdims=True)\\n        x = np.exp(x)\\n        x /= x.sum(axis=1, keepdims=True)\\n    elif x.ndim == 1:\\n        x = x - np.max(x)\\n        x = np.exp(x) / np.sum(np.exp(x))\\n    return x\\n\\n\\ndef cross_entropy_err(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n\\n    if t.size == y.size:\\n        t = t.argmax(axis=1)\\n\\n    batch_size = y.shape[0]\\n    delta = 1e-7\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + delta)) / batch_size\\n\\n\\nclass Sigmoid:\\n    def __init__(self):\\n        self.params, self.grads = [], []\\n        self.out = None\\n\\n    def forward(self, x):\\n        self.out = sigmoid(x)\\n        return self.out\\n\\n    def backward(self, dout):\\n        return dout * (1.0 - self.out) * self.out\\n\\n\\nclass Affine:\\n    def __init__(self, W, b):\\n        self.params = [W, b]\\n        self.grads = [np.zeros_like(W), np.zeros_like(b)]\\n        self.x = None\\n\\n    def forward(self, x):\\n        self.x = x\\n        W, b = self.params\\n        return np.dot(x, W) + b\\n\\n    def backward(self, dout):\\n        W, b = self.params\\n        self.grads[0][...] = np.dot(self.x.T, dout)\\n        self.grads[1][...] = np.sum(dout, axis=0)\\n        return np.dot(dout, W.T)\\n\\n\\nclass SoftmaxWithLoss:\\n    def __init__(self):\\n        self.params, self.grads = [], []\\n        self.y = None\\n        self.t = None\\n\\n    def forward(self, x, t):\\n        self.t = t\\n        self.y = softmax(x)\\n        if self.t.size == self.y.size:\\n            self.t = self.t.argmax(axis=1)\\n\\n        return cross_entropy_err(self.y, self.t)\\n\\n    def backward(self, dout=1):\\n        batch_size = self.t.shape[0]\\n        dx = self.y.copy()\\n        dx[np.arange(batch_size), self.t] -= 1\\n        dx *= dout\\n        return dx / batch_size\";\n",
       "                var nbb_formatted_code = \"def sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\n\\ndef softmax(x):\\n    if x.ndim == 2:\\n        x = x - x.max(axis=1, keepdims=True)\\n        x = np.exp(x)\\n        x /= x.sum(axis=1, keepdims=True)\\n    elif x.ndim == 1:\\n        x = x - np.max(x)\\n        x = np.exp(x) / np.sum(np.exp(x))\\n    return x\\n\\n\\ndef cross_entropy_err(y, t):\\n    if y.ndim == 1:\\n        t = t.reshape(1, t.size)\\n        y = y.reshape(1, y.size)\\n\\n    if t.size == y.size:\\n        t = t.argmax(axis=1)\\n\\n    batch_size = y.shape[0]\\n    delta = 1e-7\\n    return -np.sum(np.log(y[np.arange(batch_size), t] + delta)) / batch_size\\n\\n\\nclass Sigmoid:\\n    def __init__(self):\\n        self.params, self.grads = [], []\\n        self.out = None\\n\\n    def forward(self, x):\\n        self.out = sigmoid(x)\\n        return self.out\\n\\n    def backward(self, dout):\\n        return dout * (1.0 - self.out) * self.out\\n\\n\\nclass Affine:\\n    def __init__(self, W, b):\\n        self.params = [W, b]\\n        self.grads = [np.zeros_like(W), np.zeros_like(b)]\\n        self.x = None\\n\\n    def forward(self, x):\\n        self.x = x\\n        W, b = self.params\\n        return np.dot(x, W) + b\\n\\n    def backward(self, dout):\\n        W, b = self.params\\n        self.grads[0][...] = np.dot(self.x.T, dout)\\n        self.grads[1][...] = np.sum(dout, axis=0)\\n        return np.dot(dout, W.T)\\n\\n\\nclass SoftmaxWithLoss:\\n    def __init__(self):\\n        self.params, self.grads = [], []\\n        self.y = None\\n        self.t = None\\n\\n    def forward(self, x, t):\\n        self.t = t\\n        self.y = softmax(x)\\n        if self.t.size == self.y.size:\\n            self.t = self.t.argmax(axis=1)\\n\\n        return cross_entropy_err(self.y, self.t)\\n\\n    def backward(self, dout=1):\\n        batch_size = self.t.shape[0]\\n        dx = self.y.copy()\\n        dx[np.arange(batch_size), self.t] -= 1\\n        dx *= dout\\n        return dx / batch_size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return x\n",
    "\n",
    "\n",
    "def cross_entropy_err(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    delta = 1e-7\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + delta)) / batch_size\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = sigmoid(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * (1.0 - self.out) * self.out\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        W, b = self.params\n",
    "        return np.dot(x, W) + b\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        self.grads[0][...] = np.dot(self.x.T, dout)\n",
    "        self.grads[1][...] = np.sum(dout, axis=0)\n",
    "        return np.dot(dout, W.T)\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        return cross_entropy_err(self.y, self.t)\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        return dx / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455731e",
   "metadata": {},
   "source": [
    "#### Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "201d9657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 92;\n",
       "                var nbb_unformatted_code = \"class SGD:\\n    def __init__(self, lr=0.01):\\n        self.lr = lr\\n\\n    def update(self, params, grads):\\n        for i in range(len(params)):\\n            params[i] -= self.lr * grads[i]\";\n",
       "                var nbb_formatted_code = \"class SGD:\\n    def __init__(self, lr=0.01):\\n        self.lr = lr\\n\\n    def update(self, params, grads):\\n        for i in range(len(params)):\\n            params[i] -= self.lr * grads[i]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062afeb3",
   "metadata": {},
   "source": [
    "#### Two Layer net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7e7652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 93;\n",
       "                var nbb_unformatted_code = \"class TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size):\\n        I, H, O = input_size, hidden_size, output_size\\n\\n        W1 = 0.01 * np.random.randn(I, H)\\n        b1 = np.zeros(H)\\n        W2 = 0.01 * np.random.randn(H, O)\\n        b2 = np.zeros(O)\\n\\n        self.layers = [\\n            Affine(W1, b1),\\n            Sigmoid(),\\n            Affine(W2, b2),\\n        ]\\n        self.loss_layer = SoftmaxWithLoss()\\n\\n        self.params, self.grads = [], []\\n        for layer in self.layers:\\n            self.params += layer.params\\n            self.grads += layer.grads\\n            \\n    def predict(self, x):\\n        for layer in self.layers:\\n            x = layer.forward(x)\\n        return x\\n    \\n    def forward(self, x, t):\\n        pred = self.predict(x)\\n        return self.loss_layer.forward(pred, t)\\n    \\n    def backward(self, dout=1):\\n        dout = self.loss_layer.backward(dout)\\n        for layer in reversed(self.layers):\\n            dout = layer.backward(dout)\\n        return dout\";\n",
       "                var nbb_formatted_code = \"class TwoLayerNet:\\n    def __init__(self, input_size, hidden_size, output_size):\\n        I, H, O = input_size, hidden_size, output_size\\n\\n        W1 = 0.01 * np.random.randn(I, H)\\n        b1 = np.zeros(H)\\n        W2 = 0.01 * np.random.randn(H, O)\\n        b2 = np.zeros(O)\\n\\n        self.layers = [\\n            Affine(W1, b1),\\n            Sigmoid(),\\n            Affine(W2, b2),\\n        ]\\n        self.loss_layer = SoftmaxWithLoss()\\n\\n        self.params, self.grads = [], []\\n        for layer in self.layers:\\n            self.params += layer.params\\n            self.grads += layer.grads\\n\\n    def predict(self, x):\\n        for layer in self.layers:\\n            x = layer.forward(x)\\n        return x\\n\\n    def forward(self, x, t):\\n        pred = self.predict(x)\\n        return self.loss_layer.forward(pred, t)\\n\\n    def backward(self, dout=1):\\n        dout = self.loss_layer.backward(dout)\\n        for layer in reversed(self.layers):\\n            dout = layer.backward(dout)\\n        return dout\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        W1 = 0.01 * np.random.randn(I, H)\n",
    "        b1 = np.zeros(H)\n",
    "        W2 = 0.01 * np.random.randn(H, O)\n",
    "        b2 = np.zeros(O)\n",
    "\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2),\n",
    "        ]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        pred = self.predict(x)\n",
    "        return self.loss_layer.forward(pred, t)\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183b78e",
   "metadata": {},
   "source": [
    "#### Load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "17bd961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 2), (300, 3))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 94;\n",
       "                var nbb_unformatted_code = \"import sys\\n\\nsys.path.append(\\\"..\\\")\\nfrom dataset import spiral\\n\\nx, t = spiral.load_data()\\nx.shape, t.shape\";\n",
       "                var nbb_formatted_code = \"import sys\\n\\nsys.path.append(\\\"..\\\")\\nfrom dataset import spiral\\n\\nx, t = spiral.load_data()\\nx.shape, t.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dataset import spiral\n",
    "\n",
    "x, t = spiral.load_data()\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728d6a7",
   "metadata": {},
   "source": [
    "#### Train two net without trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96db527d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 95;\n",
       "                var nbb_unformatted_code = \"# Hypterparams\\nmax_epoch = 300\\nbatch_size = 30\\nhidden_size = 10\\nlearning_rate = 1.0\\n\\n# Load training data\\nx, t = spiral.load_data()\\nmodel = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\\noptimizer = SGD(lr=learning_rate)\\n\\ndata_size = len(x)\\nmax_iters = data_size // batch_size\\ntotal_loss = 0.0\\nloss_cout = 0.0\\nloss_list = []\";\n",
       "                var nbb_formatted_code = \"# Hypterparams\\nmax_epoch = 300\\nbatch_size = 30\\nhidden_size = 10\\nlearning_rate = 1.0\\n\\n# Load training data\\nx, t = spiral.load_data()\\nmodel = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\\noptimizer = SGD(lr=learning_rate)\\n\\ndata_size = len(x)\\nmax_iters = data_size // batch_size\\ntotal_loss = 0.0\\nloss_cout = 0.0\\nloss_list = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hypterparams\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0\n",
    "\n",
    "# Load training data\n",
    "x, t = spiral.load_data()\n",
    "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
    "optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "data_size = len(x)\n",
    "max_iters = data_size // batch_size\n",
    "total_loss = 0.0\n",
    "loss_cout = 0.0\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "60dc2c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | iter 10 / 10 | loss 1.13\n",
      "| epoch 2 | iter 10 / 10 | loss 1.13\n",
      "| epoch 3 | iter 10 / 10 | loss 1.12\n",
      "| epoch 4 | iter 10 / 10 | loss 1.12\n",
      "| epoch 5 | iter 10 / 10 | loss 1.11\n",
      "| epoch 6 | iter 10 / 10 | loss 1.14\n",
      "| epoch 7 | iter 10 / 10 | loss 1.16\n",
      "| epoch 8 | iter 10 / 10 | loss 1.11\n",
      "| epoch 9 | iter 10 / 10 | loss 1.12\n",
      "| epoch 10 | iter 10 / 10 | loss 1.13\n",
      "| epoch 11 | iter 10 / 10 | loss 1.12\n",
      "| epoch 12 | iter 10 / 10 | loss 1.11\n",
      "| epoch 13 | iter 10 / 10 | loss 1.09\n",
      "| epoch 14 | iter 10 / 10 | loss 1.08\n",
      "| epoch 15 | iter 10 / 10 | loss 1.04\n",
      "| epoch 16 | iter 10 / 10 | loss 1.03\n",
      "| epoch 17 | iter 10 / 10 | loss 0.96\n",
      "| epoch 18 | iter 10 / 10 | loss 0.92\n",
      "| epoch 19 | iter 10 / 10 | loss 0.92\n",
      "| epoch 20 | iter 10 / 10 | loss 0.87\n",
      "| epoch 21 | iter 10 / 10 | loss 0.85\n",
      "| epoch 22 | iter 10 / 10 | loss 0.82\n",
      "| epoch 23 | iter 10 / 10 | loss 0.79\n",
      "| epoch 24 | iter 10 / 10 | loss 0.78\n",
      "| epoch 25 | iter 10 / 10 | loss 0.82\n",
      "| epoch 26 | iter 10 / 10 | loss 0.78\n",
      "| epoch 27 | iter 10 / 10 | loss 0.76\n",
      "| epoch 28 | iter 10 / 10 | loss 0.76\n",
      "| epoch 29 | iter 10 / 10 | loss 0.78\n",
      "| epoch 30 | iter 10 / 10 | loss 0.75\n",
      "| epoch 31 | iter 10 / 10 | loss 0.78\n",
      "| epoch 32 | iter 10 / 10 | loss 0.77\n",
      "| epoch 33 | iter 10 / 10 | loss 0.77\n",
      "| epoch 34 | iter 10 / 10 | loss 0.78\n",
      "| epoch 35 | iter 10 / 10 | loss 0.75\n",
      "| epoch 36 | iter 10 / 10 | loss 0.74\n",
      "| epoch 37 | iter 10 / 10 | loss 0.76\n",
      "| epoch 38 | iter 10 / 10 | loss 0.76\n",
      "| epoch 39 | iter 10 / 10 | loss 0.73\n",
      "| epoch 40 | iter 10 / 10 | loss 0.75\n",
      "| epoch 41 | iter 10 / 10 | loss 0.76\n",
      "| epoch 42 | iter 10 / 10 | loss 0.76\n",
      "| epoch 43 | iter 10 / 10 | loss 0.76\n",
      "| epoch 44 | iter 10 / 10 | loss 0.74\n",
      "| epoch 45 | iter 10 / 10 | loss 0.75\n",
      "| epoch 46 | iter 10 / 10 | loss 0.73\n",
      "| epoch 47 | iter 10 / 10 | loss 0.72\n",
      "| epoch 48 | iter 10 / 10 | loss 0.73\n",
      "| epoch 49 | iter 10 / 10 | loss 0.72\n",
      "| epoch 50 | iter 10 / 10 | loss 0.72\n",
      "| epoch 51 | iter 10 / 10 | loss 0.72\n",
      "| epoch 52 | iter 10 / 10 | loss 0.72\n",
      "| epoch 53 | iter 10 / 10 | loss 0.74\n",
      "| epoch 54 | iter 10 / 10 | loss 0.74\n",
      "| epoch 55 | iter 10 / 10 | loss 0.72\n",
      "| epoch 56 | iter 10 / 10 | loss 0.72\n",
      "| epoch 57 | iter 10 / 10 | loss 0.71\n",
      "| epoch 58 | iter 10 / 10 | loss 0.70\n",
      "| epoch 59 | iter 10 / 10 | loss 0.72\n",
      "| epoch 60 | iter 10 / 10 | loss 0.70\n",
      "| epoch 61 | iter 10 / 10 | loss 0.71\n",
      "| epoch 62 | iter 10 / 10 | loss 0.72\n",
      "| epoch 63 | iter 10 / 10 | loss 0.70\n",
      "| epoch 64 | iter 10 / 10 | loss 0.71\n",
      "| epoch 65 | iter 10 / 10 | loss 0.73\n",
      "| epoch 66 | iter 10 / 10 | loss 0.70\n",
      "| epoch 67 | iter 10 / 10 | loss 0.71\n",
      "| epoch 68 | iter 10 / 10 | loss 0.69\n",
      "| epoch 69 | iter 10 / 10 | loss 0.70\n",
      "| epoch 70 | iter 10 / 10 | loss 0.71\n",
      "| epoch 71 | iter 10 / 10 | loss 0.68\n",
      "| epoch 72 | iter 10 / 10 | loss 0.69\n",
      "| epoch 73 | iter 10 / 10 | loss 0.67\n",
      "| epoch 74 | iter 10 / 10 | loss 0.68\n",
      "| epoch 75 | iter 10 / 10 | loss 0.67\n",
      "| epoch 76 | iter 10 / 10 | loss 0.66\n",
      "| epoch 77 | iter 10 / 10 | loss 0.69\n",
      "| epoch 78 | iter 10 / 10 | loss 0.64\n",
      "| epoch 79 | iter 10 / 10 | loss 0.68\n",
      "| epoch 80 | iter 10 / 10 | loss 0.64\n",
      "| epoch 81 | iter 10 / 10 | loss 0.64\n",
      "| epoch 82 | iter 10 / 10 | loss 0.66\n",
      "| epoch 83 | iter 10 / 10 | loss 0.62\n",
      "| epoch 84 | iter 10 / 10 | loss 0.62\n",
      "| epoch 85 | iter 10 / 10 | loss 0.61\n",
      "| epoch 86 | iter 10 / 10 | loss 0.60\n",
      "| epoch 87 | iter 10 / 10 | loss 0.60\n",
      "| epoch 88 | iter 10 / 10 | loss 0.61\n",
      "| epoch 89 | iter 10 / 10 | loss 0.59\n",
      "| epoch 90 | iter 10 / 10 | loss 0.58\n",
      "| epoch 91 | iter 10 / 10 | loss 0.56\n",
      "| epoch 92 | iter 10 / 10 | loss 0.56\n",
      "| epoch 93 | iter 10 / 10 | loss 0.54\n",
      "| epoch 94 | iter 10 / 10 | loss 0.53\n",
      "| epoch 95 | iter 10 / 10 | loss 0.53\n",
      "| epoch 96 | iter 10 / 10 | loss 0.52\n",
      "| epoch 97 | iter 10 / 10 | loss 0.51\n",
      "| epoch 98 | iter 10 / 10 | loss 0.50\n",
      "| epoch 99 | iter 10 / 10 | loss 0.48\n",
      "| epoch 100 | iter 10 / 10 | loss 0.48\n",
      "| epoch 101 | iter 10 / 10 | loss 0.46\n",
      "| epoch 102 | iter 10 / 10 | loss 0.45\n",
      "| epoch 103 | iter 10 / 10 | loss 0.45\n",
      "| epoch 104 | iter 10 / 10 | loss 0.44\n",
      "| epoch 105 | iter 10 / 10 | loss 0.44\n",
      "| epoch 106 | iter 10 / 10 | loss 0.41\n",
      "| epoch 107 | iter 10 / 10 | loss 0.40\n",
      "| epoch 108 | iter 10 / 10 | loss 0.41\n",
      "| epoch 109 | iter 10 / 10 | loss 0.40\n",
      "| epoch 110 | iter 10 / 10 | loss 0.40\n",
      "| epoch 111 | iter 10 / 10 | loss 0.38\n",
      "| epoch 112 | iter 10 / 10 | loss 0.38\n",
      "| epoch 113 | iter 10 / 10 | loss 0.36\n",
      "| epoch 114 | iter 10 / 10 | loss 0.37\n",
      "| epoch 115 | iter 10 / 10 | loss 0.35\n",
      "| epoch 116 | iter 10 / 10 | loss 0.34\n",
      "| epoch 117 | iter 10 / 10 | loss 0.34\n",
      "| epoch 118 | iter 10 / 10 | loss 0.34\n",
      "| epoch 119 | iter 10 / 10 | loss 0.33\n",
      "| epoch 120 | iter 10 / 10 | loss 0.34\n",
      "| epoch 121 | iter 10 / 10 | loss 0.32\n",
      "| epoch 122 | iter 10 / 10 | loss 0.32\n",
      "| epoch 123 | iter 10 / 10 | loss 0.31\n",
      "| epoch 124 | iter 10 / 10 | loss 0.31\n",
      "| epoch 125 | iter 10 / 10 | loss 0.30\n",
      "| epoch 126 | iter 10 / 10 | loss 0.30\n",
      "| epoch 127 | iter 10 / 10 | loss 0.28\n",
      "| epoch 128 | iter 10 / 10 | loss 0.28\n",
      "| epoch 129 | iter 10 / 10 | loss 0.28\n",
      "| epoch 130 | iter 10 / 10 | loss 0.28\n",
      "| epoch 131 | iter 10 / 10 | loss 0.27\n",
      "| epoch 132 | iter 10 / 10 | loss 0.27\n",
      "| epoch 133 | iter 10 / 10 | loss 0.27\n",
      "| epoch 134 | iter 10 / 10 | loss 0.27\n",
      "| epoch 135 | iter 10 / 10 | loss 0.27\n",
      "| epoch 136 | iter 10 / 10 | loss 0.26\n",
      "| epoch 137 | iter 10 / 10 | loss 0.26\n",
      "| epoch 138 | iter 10 / 10 | loss 0.26\n",
      "| epoch 139 | iter 10 / 10 | loss 0.25\n",
      "| epoch 140 | iter 10 / 10 | loss 0.24\n",
      "| epoch 141 | iter 10 / 10 | loss 0.24\n",
      "| epoch 142 | iter 10 / 10 | loss 0.25\n",
      "| epoch 143 | iter 10 / 10 | loss 0.24\n",
      "| epoch 144 | iter 10 / 10 | loss 0.24\n",
      "| epoch 145 | iter 10 / 10 | loss 0.23\n",
      "| epoch 146 | iter 10 / 10 | loss 0.24\n",
      "| epoch 147 | iter 10 / 10 | loss 0.23\n",
      "| epoch 148 | iter 10 / 10 | loss 0.23\n",
      "| epoch 149 | iter 10 / 10 | loss 0.22\n",
      "| epoch 150 | iter 10 / 10 | loss 0.22\n",
      "| epoch 151 | iter 10 / 10 | loss 0.22\n",
      "| epoch 152 | iter 10 / 10 | loss 0.22\n",
      "| epoch 153 | iter 10 / 10 | loss 0.22\n",
      "| epoch 154 | iter 10 / 10 | loss 0.22\n",
      "| epoch 155 | iter 10 / 10 | loss 0.22\n",
      "| epoch 156 | iter 10 / 10 | loss 0.21\n",
      "| epoch 157 | iter 10 / 10 | loss 0.21\n",
      "| epoch 158 | iter 10 / 10 | loss 0.20\n",
      "| epoch 159 | iter 10 / 10 | loss 0.21\n",
      "| epoch 160 | iter 10 / 10 | loss 0.20\n",
      "| epoch 161 | iter 10 / 10 | loss 0.20\n",
      "| epoch 162 | iter 10 / 10 | loss 0.20\n",
      "| epoch 163 | iter 10 / 10 | loss 0.21\n",
      "| epoch 164 | iter 10 / 10 | loss 0.20\n",
      "| epoch 165 | iter 10 / 10 | loss 0.20\n",
      "| epoch 166 | iter 10 / 10 | loss 0.19\n",
      "| epoch 167 | iter 10 / 10 | loss 0.19\n",
      "| epoch 168 | iter 10 / 10 | loss 0.19\n",
      "| epoch 169 | iter 10 / 10 | loss 0.19\n",
      "| epoch 170 | iter 10 / 10 | loss 0.19\n",
      "| epoch 171 | iter 10 / 10 | loss 0.19\n",
      "| epoch 172 | iter 10 / 10 | loss 0.18\n",
      "| epoch 173 | iter 10 / 10 | loss 0.18\n",
      "| epoch 174 | iter 10 / 10 | loss 0.18\n",
      "| epoch 175 | iter 10 / 10 | loss 0.18\n",
      "| epoch 176 | iter 10 / 10 | loss 0.18\n",
      "| epoch 177 | iter 10 / 10 | loss 0.18\n",
      "| epoch 178 | iter 10 / 10 | loss 0.18\n",
      "| epoch 179 | iter 10 / 10 | loss 0.17\n",
      "| epoch 180 | iter 10 / 10 | loss 0.17\n",
      "| epoch 181 | iter 10 / 10 | loss 0.18\n",
      "| epoch 182 | iter 10 / 10 | loss 0.17\n",
      "| epoch 183 | iter 10 / 10 | loss 0.18\n",
      "| epoch 184 | iter 10 / 10 | loss 0.17\n",
      "| epoch 185 | iter 10 / 10 | loss 0.17\n",
      "| epoch 186 | iter 10 / 10 | loss 0.18\n",
      "| epoch 187 | iter 10 / 10 | loss 0.17\n",
      "| epoch 188 | iter 10 / 10 | loss 0.17\n",
      "| epoch 189 | iter 10 / 10 | loss 0.17\n",
      "| epoch 190 | iter 10 / 10 | loss 0.17\n",
      "| epoch 191 | iter 10 / 10 | loss 0.16\n",
      "| epoch 192 | iter 10 / 10 | loss 0.17\n",
      "| epoch 193 | iter 10 / 10 | loss 0.16\n",
      "| epoch 194 | iter 10 / 10 | loss 0.16\n",
      "| epoch 195 | iter 10 / 10 | loss 0.16\n",
      "| epoch 196 | iter 10 / 10 | loss 0.16\n",
      "| epoch 197 | iter 10 / 10 | loss 0.16\n",
      "| epoch 198 | iter 10 / 10 | loss 0.15\n",
      "| epoch 199 | iter 10 / 10 | loss 0.16\n",
      "| epoch 200 | iter 10 / 10 | loss 0.16\n",
      "| epoch 201 | iter 10 / 10 | loss 0.15\n",
      "| epoch 202 | iter 10 / 10 | loss 0.16\n",
      "| epoch 203 | iter 10 / 10 | loss 0.16\n",
      "| epoch 204 | iter 10 / 10 | loss 0.15\n",
      "| epoch 205 | iter 10 / 10 | loss 0.16\n",
      "| epoch 206 | iter 10 / 10 | loss 0.15\n",
      "| epoch 207 | iter 10 / 10 | loss 0.15\n",
      "| epoch 208 | iter 10 / 10 | loss 0.15\n",
      "| epoch 209 | iter 10 / 10 | loss 0.15\n",
      "| epoch 210 | iter 10 / 10 | loss 0.15\n",
      "| epoch 211 | iter 10 / 10 | loss 0.15\n",
      "| epoch 212 | iter 10 / 10 | loss 0.15\n",
      "| epoch 213 | iter 10 / 10 | loss 0.15\n",
      "| epoch 214 | iter 10 / 10 | loss 0.15\n",
      "| epoch 215 | iter 10 / 10 | loss 0.15\n",
      "| epoch 216 | iter 10 / 10 | loss 0.14\n",
      "| epoch 217 | iter 10 / 10 | loss 0.14\n",
      "| epoch 218 | iter 10 / 10 | loss 0.15\n",
      "| epoch 219 | iter 10 / 10 | loss 0.14\n",
      "| epoch 220 | iter 10 / 10 | loss 0.14\n",
      "| epoch 221 | iter 10 / 10 | loss 0.14\n",
      "| epoch 222 | iter 10 / 10 | loss 0.14\n",
      "| epoch 223 | iter 10 / 10 | loss 0.14\n",
      "| epoch 224 | iter 10 / 10 | loss 0.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 225 | iter 10 / 10 | loss 0.14\n",
      "| epoch 226 | iter 10 / 10 | loss 0.14\n",
      "| epoch 227 | iter 10 / 10 | loss 0.14\n",
      "| epoch 228 | iter 10 / 10 | loss 0.14\n",
      "| epoch 229 | iter 10 / 10 | loss 0.13\n",
      "| epoch 230 | iter 10 / 10 | loss 0.14\n",
      "| epoch 231 | iter 10 / 10 | loss 0.13\n",
      "| epoch 232 | iter 10 / 10 | loss 0.14\n",
      "| epoch 233 | iter 10 / 10 | loss 0.13\n",
      "| epoch 234 | iter 10 / 10 | loss 0.13\n",
      "| epoch 235 | iter 10 / 10 | loss 0.13\n",
      "| epoch 236 | iter 10 / 10 | loss 0.13\n",
      "| epoch 237 | iter 10 / 10 | loss 0.14\n",
      "| epoch 238 | iter 10 / 10 | loss 0.13\n",
      "| epoch 239 | iter 10 / 10 | loss 0.13\n",
      "| epoch 240 | iter 10 / 10 | loss 0.14\n",
      "| epoch 241 | iter 10 / 10 | loss 0.13\n",
      "| epoch 242 | iter 10 / 10 | loss 0.13\n",
      "| epoch 243 | iter 10 / 10 | loss 0.13\n",
      "| epoch 244 | iter 10 / 10 | loss 0.13\n",
      "| epoch 245 | iter 10 / 10 | loss 0.13\n",
      "| epoch 246 | iter 10 / 10 | loss 0.13\n",
      "| epoch 247 | iter 10 / 10 | loss 0.13\n",
      "| epoch 248 | iter 10 / 10 | loss 0.13\n",
      "| epoch 249 | iter 10 / 10 | loss 0.13\n",
      "| epoch 250 | iter 10 / 10 | loss 0.13\n",
      "| epoch 251 | iter 10 / 10 | loss 0.13\n",
      "| epoch 252 | iter 10 / 10 | loss 0.12\n",
      "| epoch 253 | iter 10 / 10 | loss 0.12\n",
      "| epoch 254 | iter 10 / 10 | loss 0.12\n",
      "| epoch 255 | iter 10 / 10 | loss 0.12\n",
      "| epoch 256 | iter 10 / 10 | loss 0.12\n",
      "| epoch 257 | iter 10 / 10 | loss 0.12\n",
      "| epoch 258 | iter 10 / 10 | loss 0.12\n",
      "| epoch 259 | iter 10 / 10 | loss 0.13\n",
      "| epoch 260 | iter 10 / 10 | loss 0.12\n",
      "| epoch 261 | iter 10 / 10 | loss 0.13\n",
      "| epoch 262 | iter 10 / 10 | loss 0.12\n",
      "| epoch 263 | iter 10 / 10 | loss 0.12\n",
      "| epoch 264 | iter 10 / 10 | loss 0.13\n",
      "| epoch 265 | iter 10 / 10 | loss 0.12\n",
      "| epoch 266 | iter 10 / 10 | loss 0.12\n",
      "| epoch 267 | iter 10 / 10 | loss 0.12\n",
      "| epoch 268 | iter 10 / 10 | loss 0.12\n",
      "| epoch 269 | iter 10 / 10 | loss 0.11\n",
      "| epoch 270 | iter 10 / 10 | loss 0.12\n",
      "| epoch 271 | iter 10 / 10 | loss 0.12\n",
      "| epoch 272 | iter 10 / 10 | loss 0.12\n",
      "| epoch 273 | iter 10 / 10 | loss 0.12\n",
      "| epoch 274 | iter 10 / 10 | loss 0.12\n",
      "| epoch 275 | iter 10 / 10 | loss 0.11\n",
      "| epoch 276 | iter 10 / 10 | loss 0.12\n",
      "| epoch 277 | iter 10 / 10 | loss 0.12\n",
      "| epoch 278 | iter 10 / 10 | loss 0.11\n",
      "| epoch 279 | iter 10 / 10 | loss 0.11\n",
      "| epoch 280 | iter 10 / 10 | loss 0.11\n",
      "| epoch 281 | iter 10 / 10 | loss 0.11\n",
      "| epoch 282 | iter 10 / 10 | loss 0.12\n",
      "| epoch 283 | iter 10 / 10 | loss 0.11\n",
      "| epoch 284 | iter 10 / 10 | loss 0.11\n",
      "| epoch 285 | iter 10 / 10 | loss 0.11\n",
      "| epoch 286 | iter 10 / 10 | loss 0.11\n",
      "| epoch 287 | iter 10 / 10 | loss 0.11\n",
      "| epoch 288 | iter 10 / 10 | loss 0.12\n",
      "| epoch 289 | iter 10 / 10 | loss 0.11\n",
      "| epoch 290 | iter 10 / 10 | loss 0.11\n",
      "| epoch 291 | iter 10 / 10 | loss 0.11\n",
      "| epoch 292 | iter 10 / 10 | loss 0.11\n",
      "| epoch 293 | iter 10 / 10 | loss 0.11\n",
      "| epoch 294 | iter 10 / 10 | loss 0.11\n",
      "| epoch 295 | iter 10 / 10 | loss 0.12\n",
      "| epoch 296 | iter 10 / 10 | loss 0.11\n",
      "| epoch 297 | iter 10 / 10 | loss 0.12\n",
      "| epoch 298 | iter 10 / 10 | loss 0.11\n",
      "| epoch 299 | iter 10 / 10 | loss 0.11\n",
      "| epoch 300 | iter 10 / 10 | loss 0.11\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 96;\n",
       "                var nbb_unformatted_code = \"for epoch in range(max_epoch):\\n    idx = np.random.permutation(data_size)\\n    x = x[idx]\\n    t = t[idx]\\n\\n    for iters in range(max_iters):\\n        batch_x = x[iters * batch_size : (iters + 1) * batch_size]\\n        batch_t = t[iters * batch_size : (iters + 1) * batch_size]\\n        loss = model.forward(batch_x, batch_t)\\n        #         print(loss)\\n        model.backward()\\n        optimizer.update(model.params, model.grads)\\n\\n        total_loss += loss\\n        loss_cout += 1\\n\\n        if (iters + 1) % 10 == 0:\\n            avg_loss = total_loss / loss_cout\\n            print(\\n                \\\"| epoch %d | iter %d / %d | loss %.2f\\\"\\n                % (epoch + 1, iters + 1, max_iters, avg_loss)\\n            )\\n            loss_list.append(avg_loss)\\n            total_loss, loss_cout = 0.0, 0.0\";\n",
       "                var nbb_formatted_code = \"for epoch in range(max_epoch):\\n    idx = np.random.permutation(data_size)\\n    x = x[idx]\\n    t = t[idx]\\n\\n    for iters in range(max_iters):\\n        batch_x = x[iters * batch_size : (iters + 1) * batch_size]\\n        batch_t = t[iters * batch_size : (iters + 1) * batch_size]\\n        loss = model.forward(batch_x, batch_t)\\n        #         print(loss)\\n        model.backward()\\n        optimizer.update(model.params, model.grads)\\n\\n        total_loss += loss\\n        loss_cout += 1\\n\\n        if (iters + 1) % 10 == 0:\\n            avg_loss = total_loss / loss_cout\\n            print(\\n                \\\"| epoch %d | iter %d / %d | loss %.2f\\\"\\n                % (epoch + 1, iters + 1, max_iters, avg_loss)\\n            )\\n            loss_list.append(avg_loss)\\n            total_loss, loss_cout = 0.0, 0.0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    idx = np.random.permutation(data_size)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "\n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters * batch_size : (iters + 1) * batch_size]\n",
    "        batch_t = t[iters * batch_size : (iters + 1) * batch_size]\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        #         print(loss)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "\n",
    "        total_loss += loss\n",
    "        loss_cout += 1\n",
    "\n",
    "        if (iters + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / loss_cout\n",
    "            print(\n",
    "                \"| epoch %d | iter %d / %d | loss %.2f\"\n",
    "                % (epoch + 1, iters + 1, max_iters, avg_loss)\n",
    "            )\n",
    "            loss_list.append(avg_loss)\n",
    "            total_loss, loss_cout = 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb6e8ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 97;\n",
       "                var nbb_unformatted_code = \"# \\u5b66\\u7fd2\\u7d50\\u679c\\u306e\\u30d7\\u30ed\\u30c3\\u30c8\\nplt.plot(np.arange(len(loss_list)), loss_list, label=\\\"train\\\")\\nplt.xlabel(\\\"iterations (x10)\\\")\\nplt.ylabel(\\\"loss\\\")\\nplt.show()\\n\\n# \\u5883\\u754c\\u9818\\u57df\\u306e\\u30d7\\u30ed\\u30c3\\u30c8\\nh = 0.001\\nx_min, x_max = x[:, 0].min() - 0.1, x[:, 0].max() + 0.1\\ny_min, y_max = x[:, 1].min() - 0.1, x[:, 1].max() + 0.1\\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\nX = np.c_[xx.ravel(), yy.ravel()]\\nscore = model.predict(X)\\npredict_cls = np.argmax(score, axis=1)\\nZ = predict_cls.reshape(xx.shape)\\nplt.contourf(xx, yy, Z)\\nplt.axis(\\\"off\\\")\\n\\n# \\u30c7\\u30fc\\u30bf\\u70b9\\u306e\\u30d7\\u30ed\\u30c3\\u30c8\\nx, t = spiral.load_data()\\nN = 100\\nCLS_NUM = 3\\nmarkers = [\\\"o\\\", \\\"x\\\", \\\"^\\\"]\\nfor i in range(CLS_NUM):\\n    plt.scatter(\\n        x[i * N : (i + 1) * N, 0], x[i * N : (i + 1) * N, 1], s=40, marker=markers[i]\\n    )\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# \\u5b66\\u7fd2\\u7d50\\u679c\\u306e\\u30d7\\u30ed\\u30c3\\u30c8\\nplt.plot(np.arange(len(loss_list)), loss_list, label=\\\"train\\\")\\nplt.xlabel(\\\"iterations (x10)\\\")\\nplt.ylabel(\\\"loss\\\")\\nplt.show()\\n\\n# \\u5883\\u754c\\u9818\\u57df\\u306e\\u30d7\\u30ed\\u30c3\\u30c8\\nh = 0.001\\nx_min, x_max = x[:, 0].min() - 0.1, x[:, 0].max() + 0.1\\ny_min, y_max = x[:, 1].min() - 0.1, x[:, 1].max() + 0.1\\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\nX = np.c_[xx.ravel(), yy.ravel()]\\nscore = model.predict(X)\\npredict_cls = np.argmax(score, axis=1)\\nZ = predict_cls.reshape(xx.shape)\\nplt.contourf(xx, yy, Z)\\nplt.axis(\\\"off\\\")\\n\\n# \\u30c7\\u30fc\\u30bf\\u70b9\\u306e\\u30d7\\u30ed\\u30c3\\u30c8\\nx, t = spiral.load_data()\\nN = 100\\nCLS_NUM = 3\\nmarkers = [\\\"o\\\", \\\"x\\\", \\\"^\\\"]\\nfor i in range(CLS_NUM):\\n    plt.scatter(\\n        x[i * N : (i + 1) * N, 0], x[i * N : (i + 1) * N, 1], s=40, marker=markers[i]\\n    )\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習結果のプロット\n",
    "plt.plot(np.arange(len(loss_list)), loss_list, label=\"train\")\n",
    "plt.xlabel(\"iterations (x10)\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "\n",
    "# 境界領域のプロット\n",
    "h = 0.001\n",
    "x_min, x_max = x[:, 0].min() - 0.1, x[:, 0].max() + 0.1\n",
    "y_min, y_max = x[:, 1].min() - 0.1, x[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X = np.c_[xx.ravel(), yy.ravel()]\n",
    "score = model.predict(X)\n",
    "predict_cls = np.argmax(score, axis=1)\n",
    "Z = predict_cls.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# データ点のプロット\n",
    "x, t = spiral.load_data()\n",
    "N = 100\n",
    "CLS_NUM = 3\n",
    "markers = [\"o\", \"x\", \"^\"]\n",
    "for i in range(CLS_NUM):\n",
    "    plt.scatter(\n",
    "        x[i * N : (i + 1) * N, 0], x[i * N : (i + 1) * N, 1], s=40, marker=markers[i]\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb595fb",
   "metadata": {},
   "source": [
    "#### Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9fa46bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"import time\\n\\n\\nclass Trainer:\\n    def __init__(self, model, optimizer):\\n        self.model = model\\n        self.optimizer = optimizer\\n        self.loss_list = []\\n        self.eval_interval = None\\n        self.current_epoch = 0\\n\\n    def fit(self, x, t, max_epoch=10, batch_size=12, max_grad=None, eval_interval=20):\\n        data_size = len(x)\\n        max_iters = data_size // batch_size\\n        self.eval_interval = eval_interval\\n        model, optimizer = self.model, self.optimizer\\n        total_loss = 0.0\\n        loss_count = 0.0\\n\\n        start_time = time.time()\\n        for epoch in range(max_epoch):\\n            idx = np.random.permutation(np.arange(data_size))\\n            x = x[idx]\\n            t = t[idx]\\n\\n            for iters in range(max_iters):\\n                batch_x = x[iters * batch_size : (iters + 1) * batch_size]\\n                batch_t = t[iters * batch_size : (iters + 1) * batch_size]\\n\\n                loss = model.forward(batch_x, batch_t)\\n                model.backward()\\n                params, grads = remove_duplicate(model.params, model.grads)\\n                optimizer.update(params, grads)\\n                total_loss += loss\\n                loss_count += 1\\n\\n                if (eval_interval is not None) and (iters % eval_interval) == 0:\\n                    avg_loss = total_loss / loss_count\\n                    elapsed_time = time.time() - start_time\\n                    #                     print(iters)\\n                    print(\\n                        \\\"| epoch %d |  iter %d / %d | time %d[s] | loss %.2f\\\"\\n                        % (\\n                            self.current_epoch + 1,\\n                            iters + 1,\\n                            max_iters,\\n                            elapsed_time,\\n                            avg_loss,\\n                        )\\n                    )\\n                    self.loss_list.append(float(avg_loss))\\n                    total_loss, loss_count = 0.0, 0.0\\n            self.current_epoch += 1\\n\\n    def plot(self, ylim=None):\\n        x = np.arange(len(self.loss_list))\\n        if ylim is not None:\\n            plt.ylim(*ylim)\\n        plt.plot(x, self.loss_list, label=\\\"train\\\")\\n        plt.xlabel(\\\"iteration (x \\\" + str(self.eval_interval) + \\\")\\\")\\n        plt.ylabel(\\\"loss\\\")\\n        plt.show()\\n\\n\\ndef remove_duplicate(params, grads):\\n    \\\"\\\"\\\"\\n    \\u30d1\\u30e9\\u30e1\\u30fc\\u30bf\\u914d\\u5217\\u4e2d\\u306e\\u91cd\\u8907\\u3059\\u308b\\u91cd\\u307f\\u3092\\u3072\\u3068\\u3064\\u306b\\u96c6\\u7d04\\u3057\\u3001\\n    \\u305d\\u306e\\u91cd\\u307f\\u306b\\u5bfe\\u5fdc\\u3059\\u308b\\u52fe\\u914d\\u3092\\u52a0\\u7b97\\u3059\\u308b\\n    \\\"\\\"\\\"\\n    params, grads = params[:], grads[:]  # copy list\\n\\n    while True:\\n        find_flg = False\\n        L = len(params)\\n\\n        for i in range(0, L - 1):\\n            for j in range(i + 1, L):\\n                # \\u91cd\\u307f\\u3092\\u5171\\u6709\\u3059\\u308b\\u5834\\u5408\\n                if params[i] is params[j]:\\n                    grads[i] += grads[j]  # \\u52fe\\u914d\\u306e\\u52a0\\u7b97\\n                    find_flg = True\\n                    params.pop(j)\\n                    grads.pop(j)\\n                # \\u8ee2\\u7f6e\\u884c\\u5217\\u3068\\u3057\\u3066\\u91cd\\u307f\\u3092\\u5171\\u6709\\u3059\\u308b\\u5834\\u5408\\uff08weight tying\\uff09\\n                elif (\\n                    params[i].ndim == 2\\n                    and params[j].ndim == 2\\n                    and params[i].T.shape == params[j].shape\\n                    and np.all(params[i].T == params[j])\\n                ):\\n                    grads[i] += grads[j].T\\n                    find_flg = True\\n                    params.pop(j)\\n                    grads.pop(j)\\n\\n                if find_flg:\\n                    break\\n            if find_flg:\\n                break\\n\\n        if not find_flg:\\n            break\\n\\n    return params, grads\";\n",
       "                var nbb_formatted_code = \"import time\\n\\n\\nclass Trainer:\\n    def __init__(self, model, optimizer):\\n        self.model = model\\n        self.optimizer = optimizer\\n        self.loss_list = []\\n        self.eval_interval = None\\n        self.current_epoch = 0\\n\\n    def fit(self, x, t, max_epoch=10, batch_size=12, max_grad=None, eval_interval=20):\\n        data_size = len(x)\\n        max_iters = data_size // batch_size\\n        self.eval_interval = eval_interval\\n        model, optimizer = self.model, self.optimizer\\n        total_loss = 0.0\\n        loss_count = 0.0\\n\\n        start_time = time.time()\\n        for epoch in range(max_epoch):\\n            idx = np.random.permutation(np.arange(data_size))\\n            x = x[idx]\\n            t = t[idx]\\n\\n            for iters in range(max_iters):\\n                batch_x = x[iters * batch_size : (iters + 1) * batch_size]\\n                batch_t = t[iters * batch_size : (iters + 1) * batch_size]\\n\\n                loss = model.forward(batch_x, batch_t)\\n                model.backward()\\n                params, grads = remove_duplicate(model.params, model.grads)\\n                optimizer.update(params, grads)\\n                total_loss += loss\\n                loss_count += 1\\n\\n                if (eval_interval is not None) and (iters % eval_interval) == 0:\\n                    avg_loss = total_loss / loss_count\\n                    elapsed_time = time.time() - start_time\\n                    #                     print(iters)\\n                    print(\\n                        \\\"| epoch %d |  iter %d / %d | time %d[s] | loss %.2f\\\"\\n                        % (\\n                            self.current_epoch + 1,\\n                            iters + 1,\\n                            max_iters,\\n                            elapsed_time,\\n                            avg_loss,\\n                        )\\n                    )\\n                    self.loss_list.append(float(avg_loss))\\n                    total_loss, loss_count = 0.0, 0.0\\n            self.current_epoch += 1\\n\\n    def plot(self, ylim=None):\\n        x = np.arange(len(self.loss_list))\\n        if ylim is not None:\\n            plt.ylim(*ylim)\\n        plt.plot(x, self.loss_list, label=\\\"train\\\")\\n        plt.xlabel(\\\"iteration (x \\\" + str(self.eval_interval) + \\\")\\\")\\n        plt.ylabel(\\\"loss\\\")\\n        plt.show()\\n\\n\\ndef remove_duplicate(params, grads):\\n    \\\"\\\"\\\"\\n    \\u30d1\\u30e9\\u30e1\\u30fc\\u30bf\\u914d\\u5217\\u4e2d\\u306e\\u91cd\\u8907\\u3059\\u308b\\u91cd\\u307f\\u3092\\u3072\\u3068\\u3064\\u306b\\u96c6\\u7d04\\u3057\\u3001\\n    \\u305d\\u306e\\u91cd\\u307f\\u306b\\u5bfe\\u5fdc\\u3059\\u308b\\u52fe\\u914d\\u3092\\u52a0\\u7b97\\u3059\\u308b\\n    \\\"\\\"\\\"\\n    params, grads = params[:], grads[:]  # copy list\\n\\n    while True:\\n        find_flg = False\\n        L = len(params)\\n\\n        for i in range(0, L - 1):\\n            for j in range(i + 1, L):\\n                # \\u91cd\\u307f\\u3092\\u5171\\u6709\\u3059\\u308b\\u5834\\u5408\\n                if params[i] is params[j]:\\n                    grads[i] += grads[j]  # \\u52fe\\u914d\\u306e\\u52a0\\u7b97\\n                    find_flg = True\\n                    params.pop(j)\\n                    grads.pop(j)\\n                # \\u8ee2\\u7f6e\\u884c\\u5217\\u3068\\u3057\\u3066\\u91cd\\u307f\\u3092\\u5171\\u6709\\u3059\\u308b\\u5834\\u5408\\uff08weight tying\\uff09\\n                elif (\\n                    params[i].ndim == 2\\n                    and params[j].ndim == 2\\n                    and params[i].T.shape == params[j].shape\\n                    and np.all(params[i].T == params[j])\\n                ):\\n                    grads[i] += grads[j].T\\n                    find_flg = True\\n                    params.pop(j)\\n                    grads.pop(j)\\n\\n                if find_flg:\\n                    break\\n            if find_flg:\\n                break\\n\\n        if not find_flg:\\n            break\\n\\n    return params, grads\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=12, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0.0\n",
    "        loss_count = 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            idx = np.random.permutation(np.arange(data_size))\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters * batch_size : (iters + 1) * batch_size]\n",
    "                batch_t = t[iters * batch_size : (iters + 1) * batch_size]\n",
    "\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    #                     print(iters)\n",
    "                    print(\n",
    "                        \"| epoch %d |  iter %d / %d | time %d[s] | loss %.2f\"\n",
    "                        % (\n",
    "                            self.current_epoch + 1,\n",
    "                            iters + 1,\n",
    "                            max_iters,\n",
    "                            elapsed_time,\n",
    "                            avg_loss,\n",
    "                        )\n",
    "                    )\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0.0, 0.0\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = np.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label=\"train\")\n",
    "        plt.xlabel(\"iteration (x \" + str(self.eval_interval) + \")\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def remove_duplicate(params, grads):\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 重みを共有する場合\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 勾配の加算\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 転置行列として重みを共有する場合（weight tying）\n",
    "                elif (\n",
    "                    params[i].ndim == 2\n",
    "                    and params[j].ndim == 2\n",
    "                    and params[i].T.shape == params[j].shape\n",
    "                    and np.all(params[i].T == params[j])\n",
    "                ):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg:\n",
    "                    break\n",
    "            if find_flg:\n",
    "                break\n",
    "\n",
    "        if not find_flg:\n",
    "            break\n",
    "\n",
    "    return params, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "035e222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 10 | time 0[s] | loss 1.10\n",
      "| epoch 2 |  iter 1 / 10 | time 0[s] | loss 1.12\n",
      "| epoch 3 |  iter 1 / 10 | time 0[s] | loss 1.13\n",
      "| epoch 4 |  iter 1 / 10 | time 0[s] | loss 1.12\n",
      "| epoch 5 |  iter 1 / 10 | time 0[s] | loss 1.12\n",
      "| epoch 6 |  iter 1 / 10 | time 0[s] | loss 1.10\n",
      "| epoch 7 |  iter 1 / 10 | time 0[s] | loss 1.14\n",
      "| epoch 8 |  iter 1 / 10 | time 0[s] | loss 1.16\n",
      "| epoch 9 |  iter 1 / 10 | time 0[s] | loss 1.11\n",
      "| epoch 10 |  iter 1 / 10 | time 0[s] | loss 1.12\n",
      "| epoch 11 |  iter 1 / 10 | time 0[s] | loss 1.12\n",
      "| epoch 12 |  iter 1 / 10 | time 0[s] | loss 1.12\n",
      "| epoch 13 |  iter 1 / 10 | time 0[s] | loss 1.10\n",
      "| epoch 14 |  iter 1 / 10 | time 0[s] | loss 1.09\n",
      "| epoch 15 |  iter 1 / 10 | time 0[s] | loss 1.08\n",
      "| epoch 16 |  iter 1 / 10 | time 0[s] | loss 1.04\n",
      "| epoch 17 |  iter 1 / 10 | time 0[s] | loss 1.03\n",
      "| epoch 18 |  iter 1 / 10 | time 0[s] | loss 0.94\n",
      "| epoch 19 |  iter 1 / 10 | time 0[s] | loss 0.92\n",
      "| epoch 20 |  iter 1 / 10 | time 0[s] | loss 0.92\n",
      "| epoch 21 |  iter 1 / 10 | time 0[s] | loss 0.87\n",
      "| epoch 22 |  iter 1 / 10 | time 0[s] | loss 0.85\n",
      "| epoch 23 |  iter 1 / 10 | time 0[s] | loss 0.80\n",
      "| epoch 24 |  iter 1 / 10 | time 0[s] | loss 0.79\n",
      "| epoch 25 |  iter 1 / 10 | time 0[s] | loss 0.78\n",
      "| epoch 26 |  iter 1 / 10 | time 0[s] | loss 0.83\n",
      "| epoch 27 |  iter 1 / 10 | time 0[s] | loss 0.77\n",
      "| epoch 28 |  iter 1 / 10 | time 0[s] | loss 0.76\n",
      "| epoch 29 |  iter 1 / 10 | time 0[s] | loss 0.77\n",
      "| epoch 30 |  iter 1 / 10 | time 0[s] | loss 0.76\n",
      "| epoch 31 |  iter 1 / 10 | time 0[s] | loss 0.77\n",
      "| epoch 32 |  iter 1 / 10 | time 0[s] | loss 0.75\n",
      "| epoch 33 |  iter 1 / 10 | time 0[s] | loss 0.78\n",
      "| epoch 34 |  iter 1 / 10 | time 0[s] | loss 0.77\n",
      "| epoch 35 |  iter 1 / 10 | time 0[s] | loss 0.78\n",
      "| epoch 36 |  iter 1 / 10 | time 0[s] | loss 0.74\n",
      "| epoch 37 |  iter 1 / 10 | time 0[s] | loss 0.75\n",
      "| epoch 38 |  iter 1 / 10 | time 0[s] | loss 0.77\n",
      "| epoch 39 |  iter 1 / 10 | time 0[s] | loss 0.75\n",
      "| epoch 40 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 41 |  iter 1 / 10 | time 0[s] | loss 0.75\n",
      "| epoch 42 |  iter 1 / 10 | time 0[s] | loss 0.76\n",
      "| epoch 43 |  iter 1 / 10 | time 0[s] | loss 0.79\n",
      "| epoch 44 |  iter 1 / 10 | time 0[s] | loss 0.74\n",
      "| epoch 45 |  iter 1 / 10 | time 0[s] | loss 0.75\n",
      "| epoch 46 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 47 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 48 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 49 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 50 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 51 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 52 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 53 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 54 |  iter 1 / 10 | time 0[s] | loss 0.74\n",
      "| epoch 55 |  iter 1 / 10 | time 0[s] | loss 0.74\n",
      "| epoch 56 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 57 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 58 |  iter 1 / 10 | time 0[s] | loss 0.69\n",
      "| epoch 59 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 60 |  iter 1 / 10 | time 0[s] | loss 0.70\n",
      "| epoch 61 |  iter 1 / 10 | time 0[s] | loss 0.69\n",
      "| epoch 62 |  iter 1 / 10 | time 0[s] | loss 0.71\n",
      "| epoch 63 |  iter 1 / 10 | time 0[s] | loss 0.70\n",
      "| epoch 64 |  iter 1 / 10 | time 0[s] | loss 0.71\n",
      "| epoch 65 |  iter 1 / 10 | time 0[s] | loss 0.72\n",
      "| epoch 66 |  iter 1 / 10 | time 0[s] | loss 0.71\n",
      "| epoch 67 |  iter 1 / 10 | time 0[s] | loss 0.71\n",
      "| epoch 68 |  iter 1 / 10 | time 0[s] | loss 0.71\n",
      "| epoch 69 |  iter 1 / 10 | time 0[s] | loss 0.70\n",
      "| epoch 70 |  iter 1 / 10 | time 0[s] | loss 0.68\n",
      "| epoch 71 |  iter 1 / 10 | time 0[s] | loss 0.73\n",
      "| epoch 72 |  iter 1 / 10 | time 0[s] | loss 0.66\n",
      "| epoch 73 |  iter 1 / 10 | time 0[s] | loss 0.69\n",
      "| epoch 74 |  iter 1 / 10 | time 0[s] | loss 0.66\n",
      "| epoch 75 |  iter 1 / 10 | time 0[s] | loss 0.70\n",
      "| epoch 76 |  iter 1 / 10 | time 0[s] | loss 0.65\n",
      "| epoch 77 |  iter 1 / 10 | time 0[s] | loss 0.67\n",
      "| epoch 78 |  iter 1 / 10 | time 0[s] | loss 0.70\n",
      "| epoch 79 |  iter 1 / 10 | time 0[s] | loss 0.63\n",
      "| epoch 80 |  iter 1 / 10 | time 0[s] | loss 0.66\n",
      "| epoch 81 |  iter 1 / 10 | time 0[s] | loss 0.65\n",
      "| epoch 82 |  iter 1 / 10 | time 0[s] | loss 0.66\n",
      "| epoch 83 |  iter 1 / 10 | time 0[s] | loss 0.64\n",
      "| epoch 84 |  iter 1 / 10 | time 0[s] | loss 0.62\n",
      "| epoch 85 |  iter 1 / 10 | time 0[s] | loss 0.62\n",
      "| epoch 86 |  iter 1 / 10 | time 0[s] | loss 0.63\n",
      "| epoch 87 |  iter 1 / 10 | time 0[s] | loss 0.59\n",
      "| epoch 88 |  iter 1 / 10 | time 0[s] | loss 0.58\n",
      "| epoch 89 |  iter 1 / 10 | time 0[s] | loss 0.61\n",
      "| epoch 90 |  iter 1 / 10 | time 0[s] | loss 0.59\n",
      "| epoch 91 |  iter 1 / 10 | time 0[s] | loss 0.58\n",
      "| epoch 92 |  iter 1 / 10 | time 0[s] | loss 0.57\n",
      "| epoch 93 |  iter 1 / 10 | time 0[s] | loss 0.55\n",
      "| epoch 94 |  iter 1 / 10 | time 0[s] | loss 0.54\n",
      "| epoch 95 |  iter 1 / 10 | time 0[s] | loss 0.53\n",
      "| epoch 96 |  iter 1 / 10 | time 0[s] | loss 0.54\n",
      "| epoch 97 |  iter 1 / 10 | time 0[s] | loss 0.51\n",
      "| epoch 98 |  iter 1 / 10 | time 0[s] | loss 0.51\n",
      "| epoch 99 |  iter 1 / 10 | time 0[s] | loss 0.50\n",
      "| epoch 100 |  iter 1 / 10 | time 0[s] | loss 0.47\n",
      "| epoch 101 |  iter 1 / 10 | time 0[s] | loss 0.49\n",
      "| epoch 102 |  iter 1 / 10 | time 0[s] | loss 0.46\n",
      "| epoch 103 |  iter 1 / 10 | time 0[s] | loss 0.44\n",
      "| epoch 104 |  iter 1 / 10 | time 0[s] | loss 0.47\n",
      "| epoch 105 |  iter 1 / 10 | time 0[s] | loss 0.44\n",
      "| epoch 106 |  iter 1 / 10 | time 0[s] | loss 0.43\n",
      "| epoch 107 |  iter 1 / 10 | time 0[s] | loss 0.43\n",
      "| epoch 108 |  iter 1 / 10 | time 0[s] | loss 0.39\n",
      "| epoch 109 |  iter 1 / 10 | time 0[s] | loss 0.40\n",
      "| epoch 110 |  iter 1 / 10 | time 0[s] | loss 0.41\n",
      "| epoch 111 |  iter 1 / 10 | time 0[s] | loss 0.38\n",
      "| epoch 112 |  iter 1 / 10 | time 0[s] | loss 0.38\n",
      "| epoch 113 |  iter 1 / 10 | time 0[s] | loss 0.38\n",
      "| epoch 114 |  iter 1 / 10 | time 0[s] | loss 0.37\n",
      "| epoch 115 |  iter 1 / 10 | time 0[s] | loss 0.36\n",
      "| epoch 116 |  iter 1 / 10 | time 0[s] | loss 0.34\n",
      "| epoch 117 |  iter 1 / 10 | time 0[s] | loss 0.35\n",
      "| epoch 118 |  iter 1 / 10 | time 0[s] | loss 0.33\n",
      "| epoch 119 |  iter 1 / 10 | time 0[s] | loss 0.35\n",
      "| epoch 120 |  iter 1 / 10 | time 0[s] | loss 0.33\n",
      "| epoch 121 |  iter 1 / 10 | time 0[s] | loss 0.33\n",
      "| epoch 122 |  iter 1 / 10 | time 0[s] | loss 0.32\n",
      "| epoch 123 |  iter 1 / 10 | time 0[s] | loss 0.31\n",
      "| epoch 124 |  iter 1 / 10 | time 0[s] | loss 0.31\n",
      "| epoch 125 |  iter 1 / 10 | time 0[s] | loss 0.31\n",
      "| epoch 126 |  iter 1 / 10 | time 0[s] | loss 0.30\n",
      "| epoch 127 |  iter 1 / 10 | time 0[s] | loss 0.30\n",
      "| epoch 128 |  iter 1 / 10 | time 0[s] | loss 0.27\n",
      "| epoch 129 |  iter 1 / 10 | time 0[s] | loss 0.30\n",
      "| epoch 130 |  iter 1 / 10 | time 0[s] | loss 0.28\n",
      "| epoch 131 |  iter 1 / 10 | time 0[s] | loss 0.26\n",
      "| epoch 132 |  iter 1 / 10 | time 0[s] | loss 0.27\n",
      "| epoch 133 |  iter 1 / 10 | time 0[s] | loss 0.27\n",
      "| epoch 134 |  iter 1 / 10 | time 0[s] | loss 0.28\n",
      "| epoch 135 |  iter 1 / 10 | time 0[s] | loss 0.26\n",
      "| epoch 136 |  iter 1 / 10 | time 0[s] | loss 0.28\n",
      "| epoch 137 |  iter 1 / 10 | time 0[s] | loss 0.25\n",
      "| epoch 138 |  iter 1 / 10 | time 0[s] | loss 0.26\n",
      "| epoch 139 |  iter 1 / 10 | time 0[s] | loss 0.26\n",
      "| epoch 140 |  iter 1 / 10 | time 0[s] | loss 0.26\n",
      "| epoch 141 |  iter 1 / 10 | time 0[s] | loss 0.23\n",
      "| epoch 142 |  iter 1 / 10 | time 0[s] | loss 0.23\n",
      "| epoch 143 |  iter 1 / 10 | time 0[s] | loss 0.26\n",
      "| epoch 144 |  iter 1 / 10 | time 0[s] | loss 0.23\n",
      "| epoch 145 |  iter 1 / 10 | time 0[s] | loss 0.24\n",
      "| epoch 146 |  iter 1 / 10 | time 0[s] | loss 0.24\n",
      "| epoch 147 |  iter 1 / 10 | time 0[s] | loss 0.25\n",
      "| epoch 148 |  iter 1 / 10 | time 0[s] | loss 0.21\n",
      "| epoch 149 |  iter 1 / 10 | time 0[s] | loss 0.23\n",
      "| epoch 150 |  iter 1 / 10 | time 0[s] | loss 0.22\n",
      "| epoch 151 |  iter 1 / 10 | time 0[s] | loss 0.22\n",
      "| epoch 152 |  iter 1 / 10 | time 0[s] | loss 0.23\n",
      "| epoch 153 |  iter 1 / 10 | time 0[s] | loss 0.23\n",
      "| epoch 154 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 155 |  iter 1 / 10 | time 0[s] | loss 0.22\n",
      "| epoch 156 |  iter 1 / 10 | time 0[s] | loss 0.21\n",
      "| epoch 157 |  iter 1 / 10 | time 0[s] | loss 0.21\n",
      "| epoch 158 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 159 |  iter 1 / 10 | time 0[s] | loss 0.21\n",
      "| epoch 160 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 161 |  iter 1 / 10 | time 0[s] | loss 0.19\n",
      "| epoch 162 |  iter 1 / 10 | time 0[s] | loss 0.22\n",
      "| epoch 163 |  iter 1 / 10 | time 0[s] | loss 0.19\n",
      "| epoch 164 |  iter 1 / 10 | time 0[s] | loss 0.21\n",
      "| epoch 165 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 166 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 167 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 168 |  iter 1 / 10 | time 0[s] | loss 0.19\n",
      "| epoch 169 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 170 |  iter 1 / 10 | time 0[s] | loss 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 171 |  iter 1 / 10 | time 0[s] | loss 0.19\n",
      "| epoch 172 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 173 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 174 |  iter 1 / 10 | time 0[s] | loss 0.20\n",
      "| epoch 175 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 176 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 177 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 178 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 179 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 180 |  iter 1 / 10 | time 0[s] | loss 0.19\n",
      "| epoch 181 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 182 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 183 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 184 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 185 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 186 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 187 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 188 |  iter 1 / 10 | time 0[s] | loss 0.18\n",
      "| epoch 189 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 190 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 191 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 192 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 193 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 194 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 195 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 196 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 197 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 198 |  iter 1 / 10 | time 0[s] | loss 0.17\n",
      "| epoch 199 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 200 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 201 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 202 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 203 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 204 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 205 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 206 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 207 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 208 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 209 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 210 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 211 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 212 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 213 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 214 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 215 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 216 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 217 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 218 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 219 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 220 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 221 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 222 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 223 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 224 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 225 |  iter 1 / 10 | time 0[s] | loss 0.16\n",
      "| epoch 226 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 227 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 228 |  iter 1 / 10 | time 0[s] | loss 0.15\n",
      "| epoch 229 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 230 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 231 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 232 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 233 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 234 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 235 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 236 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 237 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 238 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 239 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 240 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 241 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 242 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 243 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 244 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 245 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 246 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 247 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 248 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 249 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 250 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 251 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 252 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 253 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 254 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 255 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 256 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 257 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 258 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 259 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 260 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 261 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 262 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 263 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 264 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 265 |  iter 1 / 10 | time 0[s] | loss 0.14\n",
      "| epoch 266 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 267 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 268 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 269 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 270 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 271 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 272 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 273 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 274 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 275 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 276 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 277 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 278 |  iter 1 / 10 | time 0[s] | loss 0.13\n",
      "| epoch 279 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 280 |  iter 1 / 10 | time 0[s] | loss 0.10\n",
      "| epoch 281 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 282 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 283 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 284 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 285 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 286 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 287 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 288 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 289 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 290 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 291 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 292 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 293 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 294 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 295 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 296 |  iter 1 / 10 | time 0[s] | loss 0.12\n",
      "| epoch 297 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 298 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 299 |  iter 1 / 10 | time 0[s] | loss 0.11\n",
      "| epoch 300 |  iter 1 / 10 | time 0[s] | loss 0.11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 105;\n",
       "                var nbb_unformatted_code = \"max_epoch = 300\\nbatch_size = 30\\nhidden_size = 10\\nlearning_rate = 1.0\\n\\nx, t = spiral.load_data()\\nmodel = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\\noptimizer = SGD(lr=learning_rate)\\n\\ntrainer = Trainer(model, optimizer)\\ntrainer.fit(x, t, max_epoch, batch_size, eval_interval=10)\\ntrainer.plot()\";\n",
       "                var nbb_formatted_code = \"max_epoch = 300\\nbatch_size = 30\\nhidden_size = 10\\nlearning_rate = 1.0\\n\\nx, t = spiral.load_data()\\nmodel = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\\noptimizer = SGD(lr=learning_rate)\\n\\ntrainer = Trainer(model, optimizer)\\ntrainer.fit(x, t, max_epoch, batch_size, eval_interval=10)\\ntrainer.plot()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0\n",
    "\n",
    "x, t = spiral.load_data()\n",
    "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
    "optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(x, t, max_epoch, batch_size, eval_interval=10)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb7b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
